
######## Initializing Models ########
######## Using GAN Architecture ########

[Processing Pair 1/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1019/00014.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1019/00014.wav
Generated Mel Shape: torch.Size([1, 128, 134]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 134]), Reference Mel Shape: torch.Size([1, 128, 134])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 2/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1037/00007.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1037/00007.wav
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 131])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 3/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1037/00027.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1037/00027.wav
Generated Mel Shape: torch.Size([1, 128, 163]), Reference Mel Shape: torch.Size([1, 128, 288])
Generated Mel Shape: torch.Size([1, 128, 163]), Reference Mel Shape: torch.Size([1, 128, 163])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 163])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 163])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 163])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 163])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 4/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1096/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1096/00011.wav
Generated Mel Shape: torch.Size([1, 128, 192]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 179]), Reference Mel Shape: torch.Size([1, 128, 179])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 179])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 179])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 179])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 179])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 5/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1096/00040.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1096/00040.wav
Generated Mel Shape: torch.Size([1, 128, 273]), Reference Mel Shape: torch.Size([1, 128, 256])
Generated Mel Shape: torch.Size([1, 128, 256]), Reference Mel Shape: torch.Size([1, 128, 256])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 256])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 256])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 256])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 256])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])

[Processing Pair 6/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1114/00001.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1114/00001.wav
Generated Mel Shape: torch.Size([1, 128, 209]), Reference Mel Shape: torch.Size([1, 128, 243])
Generated Mel Shape: torch.Size([1, 128, 209]), Reference Mel Shape: torch.Size([1, 128, 209])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 209])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 209])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 105])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 209])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 209])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 105])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])

[Processing Pair 7/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1114/00007.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1114/00007.wav
Generated Mel Shape: torch.Size([1, 128, 280]), Reference Mel Shape: torch.Size([1, 128, 326])
Generated Mel Shape: torch.Size([1, 128, 280]), Reference Mel Shape: torch.Size([1, 128, 280])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 280])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 280])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 35])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4480])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 280])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 280])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 35])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4480])

[Processing Pair 8/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1114/00009.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1114/00009.wav
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 131])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 9/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1114/00018.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1114/00018.wav
Generated Mel Shape: torch.Size([1, 128, 186]), Reference Mel Shape: torch.Size([1, 128, 217])
Generated Mel Shape: torch.Size([1, 128, 186]), Reference Mel Shape: torch.Size([1, 128, 186])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 186])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 186])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 93])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 186])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 186])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 93])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 10/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1114/00023.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1114/00023.wav
Generated Mel Shape: torch.Size([1, 128, 408]), Reference Mel Shape: torch.Size([1, 128, 454])
Generated Mel Shape: torch.Size([1, 128, 408]), Reference Mel Shape: torch.Size([1, 128, 408])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 408])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 408])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 204])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 51])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 51])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 6528])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 408])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 408])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 204])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 51])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 51])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 6528])

[Processing Pair 11/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1114/00031.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1114/00031.wav
Generated Mel Shape: torch.Size([1, 128, 104]), Reference Mel Shape: torch.Size([1, 128, 198])
Generated Mel Shape: torch.Size([1, 128, 104]), Reference Mel Shape: torch.Size([1, 128, 104])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 104])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 104])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 104])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 104])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])

[Processing Pair 12/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1114/00035.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1114/00035.wav
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 131])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 13/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1263/00003.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1263/00003.wav
Generated Mel Shape: torch.Size([1, 128, 121]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 121]), Reference Mel Shape: torch.Size([1, 128, 121])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 121])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 121])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 121])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 121])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 14/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1288/00007.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1288/00007.wav
Generated Mel Shape: torch.Size([1, 128, 149]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 15/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1404/00008.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1404/00008.wav
Generated Mel Shape: torch.Size([1, 128, 130]), Reference Mel Shape: torch.Size([1, 128, 211])
Generated Mel Shape: torch.Size([1, 128, 130]), Reference Mel Shape: torch.Size([1, 128, 130])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 130])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 130])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 130])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 130])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 16/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1404/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1404/00011.wav
Generated Mel Shape: torch.Size([1, 128, 130]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 130]), Reference Mel Shape: torch.Size([1, 128, 130])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 130])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 130])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 130])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 130])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 17/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1404/00024.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1404/00024.wav
Generated Mel Shape: torch.Size([1, 128, 122]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 122]), Reference Mel Shape: torch.Size([1, 128, 122])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 122])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 122])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 122])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 122])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 18/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1404/00026.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1404/00026.wav
Generated Mel Shape: torch.Size([1, 128, 167]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 19/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1474/00019.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1474/00019.wav
Generated Mel Shape: torch.Size([1, 128, 312]), Reference Mel Shape: torch.Size([1, 128, 320])
Generated Mel Shape: torch.Size([1, 128, 312]), Reference Mel Shape: torch.Size([1, 128, 312])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 312])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 312])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 156])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 78])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 39])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 39])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4992])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 312])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 312])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 156])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 78])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 39])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 39])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4992])

[Processing Pair 20/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1538/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1538/00006.wav
Generated Mel Shape: torch.Size([1, 128, 87]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 87]), Reference Mel Shape: torch.Size([1, 128, 87])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 87])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 87])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 11])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1408])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 87])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 87])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 11])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1408])

[Processing Pair 21/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1538/00019.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1538/00019.wav
Generated Mel Shape: torch.Size([1, 128, 182]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 182]), Reference Mel Shape: torch.Size([1, 128, 182])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 182])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 182])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 91])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 182])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 182])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 91])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 22/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1538/00020.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1538/00020.wav
Generated Mel Shape: torch.Size([1, 128, 150]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 150]), Reference Mel Shape: torch.Size([1, 128, 150])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 150])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 150])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 75])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 150])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 150])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 75])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 23/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1538/00036.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1538/00036.wav
Generated Mel Shape: torch.Size([1, 128, 163]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 163]), Reference Mel Shape: torch.Size([1, 128, 163])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 163])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 163])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 163])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 163])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 24/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1610/00003.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1610/00003.wav
Generated Mel Shape: torch.Size([1, 128, 180]), Reference Mel Shape: torch.Size([1, 128, 249])
Generated Mel Shape: torch.Size([1, 128, 180]), Reference Mel Shape: torch.Size([1, 128, 180])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 180])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 180])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 180])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 180])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 25/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1610/00008.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1610/00008.wav
Generated Mel Shape: torch.Size([1, 128, 124]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 124]), Reference Mel Shape: torch.Size([1, 128, 124])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 124])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 124])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 62])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 124])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 124])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 62])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 26/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1610/00038.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1610/00038.wav
Generated Mel Shape: torch.Size([1, 128, 173]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 166]), Reference Mel Shape: torch.Size([1, 128, 166])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 166])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 166])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 27/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1610/00071.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1610/00071.wav
Generated Mel Shape: torch.Size([1, 128, 166]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 166]), Reference Mel Shape: torch.Size([1, 128, 166])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 166])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 166])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 28/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1610/00112.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1610/00112.wav
Generated Mel Shape: torch.Size([1, 128, 262]), Reference Mel Shape: torch.Size([1, 128, 268])
Generated Mel Shape: torch.Size([1, 128, 262]), Reference Mel Shape: torch.Size([1, 128, 262])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 262])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 262])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 33])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4224])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 262])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 262])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 33])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4224])

[Processing Pair 29/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1611/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1611/00002.wav
Generated Mel Shape: torch.Size([1, 128, 135]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 135]), Reference Mel Shape: torch.Size([1, 128, 135])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 135])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 135])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 68])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 135])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 135])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 68])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 30/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1611/00022.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1611/00022.wav
Generated Mel Shape: torch.Size([1, 128, 219]), Reference Mel Shape: torch.Size([1, 128, 249])
Generated Mel Shape: torch.Size([1, 128, 219]), Reference Mel Shape: torch.Size([1, 128, 219])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 219])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 219])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 110])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 55])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 219])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 219])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 110])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 55])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])

[Processing Pair 31/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1611/00030.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1611/00030.wav
Generated Mel Shape: torch.Size([1, 128, 165]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 165]), Reference Mel Shape: torch.Size([1, 128, 165])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 165])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 165])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 165])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 165])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 32/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1611/00036.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1611/00036.wav
Generated Mel Shape: torch.Size([1, 128, 116]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 116]), Reference Mel Shape: torch.Size([1, 128, 116])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 116])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 116])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 33/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1611/00106.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1611/00106.wav
Generated Mel Shape: torch.Size([1, 128, 273]), Reference Mel Shape: torch.Size([1, 128, 307])
Generated Mel Shape: torch.Size([1, 128, 273]), Reference Mel Shape: torch.Size([1, 128, 273])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 273])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 273])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 137])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 69])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 35])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4480])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 273])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 273])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 137])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 69])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 35])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4480])

[Processing Pair 34/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1637/00016.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1637/00016.wav
Generated Mel Shape: torch.Size([1, 128, 115]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 115]), Reference Mel Shape: torch.Size([1, 128, 115])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 115])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 115])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 115])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 115])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 35/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1667/00020.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1667/00020.wav
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 160]), Reference Mel Shape: torch.Size([1, 128, 160])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 36/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1692/00106.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1692/00106.wav
Generated Mel Shape: torch.Size([1, 128, 112]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 112]), Reference Mel Shape: torch.Size([1, 128, 112])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 112])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 112])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 37/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1728/00024.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1728/00024.wav
Generated Mel Shape: torch.Size([1, 128, 190]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 190]), Reference Mel Shape: torch.Size([1, 128, 190])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 190])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 190])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 95])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 190])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 190])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 95])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 38/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1747/00078.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1747/00078.wav
Generated Mel Shape: torch.Size([1, 128, 399]), Reference Mel Shape: torch.Size([1, 128, 300])
Generated Mel Shape: torch.Size([1, 128, 300]), Reference Mel Shape: torch.Size([1, 128, 300])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 300])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 300])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 150])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 75])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 38])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4864])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 300])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 300])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 150])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 75])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 38])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4864])

[Processing Pair 39/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1766/00043.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1766/00043.wav
Generated Mel Shape: torch.Size([1, 128, 89]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 89]), Reference Mel Shape: torch.Size([1, 128, 89])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 89])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 89])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])

[Processing Pair 40/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk179/00014.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk179/00014.wav
Generated Mel Shape: torch.Size([1, 128, 192]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 192]), Reference Mel Shape: torch.Size([1, 128, 192])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 192])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 192])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 192])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 192])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 41/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1826/00018.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1826/00018.wav
Generated Mel Shape: torch.Size([1, 128, 322]), Reference Mel Shape: torch.Size([1, 128, 409])
Generated Mel Shape: torch.Size([1, 128, 322]), Reference Mel Shape: torch.Size([1, 128, 322])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 322])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 322])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 161])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 41])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 41])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5248])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 322])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 322])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 161])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 41])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 41])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5248])

[Processing Pair 42/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1826/00119.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1826/00119.wav
Generated Mel Shape: torch.Size([1, 128, 146]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 43/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1827/00045.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1827/00045.wav
Generated Mel Shape: torch.Size([1, 128, 248]), Reference Mel Shape: torch.Size([1, 128, 236])
Generated Mel Shape: torch.Size([1, 128, 236]), Reference Mel Shape: torch.Size([1, 128, 236])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 236])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 236])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 118])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 30])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3840])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 236])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 236])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 118])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 30])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3840])

[Processing Pair 44/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk184/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk184/00011.wav
Generated Mel Shape: torch.Size([1, 128, 95]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 95]), Reference Mel Shape: torch.Size([1, 128, 95])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 95])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 95])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 95])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 95])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])

[Processing Pair 45/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk187/00007.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk187/00007.wav
Generated Mel Shape: torch.Size([1, 128, 132]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 132]), Reference Mel Shape: torch.Size([1, 128, 132])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 132])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 132])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 132])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 132])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 46/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk187/00022.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk187/00022.wav
Generated Mel Shape: torch.Size([1, 128, 136]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 136]), Reference Mel Shape: torch.Size([1, 128, 136])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 136])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 136])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 68])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 136])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 136])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 68])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 47/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1946/00016.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1946/00016.wav
Generated Mel Shape: torch.Size([1, 128, 141]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 141]), Reference Mel Shape: torch.Size([1, 128, 141])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 141])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 141])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 48/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1946/00051.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1946/00051.wav
Generated Mel Shape: torch.Size([1, 128, 136]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 136]), Reference Mel Shape: torch.Size([1, 128, 136])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 136])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 136])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 68])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 136])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 136])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 68])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 49/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1946/00057.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1946/00057.wav
Generated Mel Shape: torch.Size([1, 128, 300]), Reference Mel Shape: torch.Size([1, 128, 384])
Generated Mel Shape: torch.Size([1, 128, 300]), Reference Mel Shape: torch.Size([1, 128, 300])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 300])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 300])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 150])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 75])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 38])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4864])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 300])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 300])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 150])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 75])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 38])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4864])

[Processing Pair 50/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1946/00089.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1946/00089.wav
Generated Mel Shape: torch.Size([1, 128, 198]), Reference Mel Shape: torch.Size([1, 128, 262])
Generated Mel Shape: torch.Size([1, 128, 198]), Reference Mel Shape: torch.Size([1, 128, 198])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 198])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 198])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 99])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 198])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 198])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 99])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])

[Processing Pair 51/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk1946/00098.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk1946/00098.wav
Generated Mel Shape: torch.Size([1, 128, 167]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 167]), Reference Mel Shape: torch.Size([1, 128, 167])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 167])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 167])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 84])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 167])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 167])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 84])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 52/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk203/00001.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk203/00001.wav
Generated Mel Shape: torch.Size([1, 128, 129]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 129]), Reference Mel Shape: torch.Size([1, 128, 129])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 129])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 129])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 129])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 129])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 53/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2052/00001.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2052/00001.wav
Generated Mel Shape: torch.Size([1, 128, 173]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 172]), Reference Mel Shape: torch.Size([1, 128, 172])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 54/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2052/00005.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2052/00005.wav
Generated Mel Shape: torch.Size([1, 128, 156]), Reference Mel Shape: torch.Size([1, 128, 198])
Generated Mel Shape: torch.Size([1, 128, 156]), Reference Mel Shape: torch.Size([1, 128, 156])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 156])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 156])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 78])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 156])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 156])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 78])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 55/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2052/00018.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2052/00018.wav
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 56/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2052/00020.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2052/00020.wav
Generated Mel Shape: torch.Size([1, 128, 261]), Reference Mel Shape: torch.Size([1, 128, 249])
Generated Mel Shape: torch.Size([1, 128, 249]), Reference Mel Shape: torch.Size([1, 128, 249])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 249])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 249])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 125])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 63])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 249])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 249])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 125])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 63])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])

[Processing Pair 57/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2052/00021.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2052/00021.wav
Generated Mel Shape: torch.Size([1, 128, 150]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 150]), Reference Mel Shape: torch.Size([1, 128, 150])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 150])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 150])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 75])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 150])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 150])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 75])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 58/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2052/00035.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2052/00035.wav
Generated Mel Shape: torch.Size([1, 128, 403]), Reference Mel Shape: torch.Size([1, 128, 460])
Generated Mel Shape: torch.Size([1, 128, 403]), Reference Mel Shape: torch.Size([1, 128, 403])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 403])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 403])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 202])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 51])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 51])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 6528])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 403])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 403])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 202])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 51])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 51])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 6528])

[Processing Pair 59/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2052/00036.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2052/00036.wav
Generated Mel Shape: torch.Size([1, 128, 194]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 192]), Reference Mel Shape: torch.Size([1, 128, 192])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 192])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 192])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 192])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 192])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 60/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2057/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2057/00006.wav
Generated Mel Shape: torch.Size([1, 128, 123]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 123]), Reference Mel Shape: torch.Size([1, 128, 123])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 123])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 123])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 62])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 123])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 123])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 62])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 61/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2057/00024.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2057/00024.wav
Generated Mel Shape: torch.Size([1, 128, 164]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 164]), Reference Mel Shape: torch.Size([1, 128, 164])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 164])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 164])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 164])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 164])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 62/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2077/00004.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2077/00004.wav
Generated Mel Shape: torch.Size([1, 128, 151]), Reference Mel Shape: torch.Size([1, 128, 217])
Generated Mel Shape: torch.Size([1, 128, 151]), Reference Mel Shape: torch.Size([1, 128, 151])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 151])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 151])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 151])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 151])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 63/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2077/00054.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2077/00054.wav
Generated Mel Shape: torch.Size([1, 128, 189]), Reference Mel Shape: torch.Size([1, 128, 300])
Generated Mel Shape: torch.Size([1, 128, 189]), Reference Mel Shape: torch.Size([1, 128, 189])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 189])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 189])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 95])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 189])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 189])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 95])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 64/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2077/00065.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2077/00065.wav
Generated Mel Shape: torch.Size([1, 128, 175]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 147]), Reference Mel Shape: torch.Size([1, 128, 147])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 147])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 147])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 65/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2088/00001.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2088/00001.wav
Generated Mel Shape: torch.Size([1, 128, 182]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 179]), Reference Mel Shape: torch.Size([1, 128, 179])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 179])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 179])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 179])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 179])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 66/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2088/00058.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2088/00058.wav
Generated Mel Shape: torch.Size([1, 128, 149]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 149]), Reference Mel Shape: torch.Size([1, 128, 149])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 149])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 149])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 75])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 149])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 149])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 75])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 67/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2093/00019.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2093/00019.wav
Generated Mel Shape: torch.Size([1, 128, 114]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 114]), Reference Mel Shape: torch.Size([1, 128, 114])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 114])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 114])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 114])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 114])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 68/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2093/00031.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2093/00031.wav
Generated Mel Shape: torch.Size([1, 128, 204]), Reference Mel Shape: torch.Size([1, 128, 262])
Generated Mel Shape: torch.Size([1, 128, 204]), Reference Mel Shape: torch.Size([1, 128, 204])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 204])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 204])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 204])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 204])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])

[Processing Pair 69/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2098/00031.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2098/00031.wav
Generated Mel Shape: torch.Size([1, 128, 398]), Reference Mel Shape: torch.Size([1, 128, 448])
Generated Mel Shape: torch.Size([1, 128, 398]), Reference Mel Shape: torch.Size([1, 128, 398])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 398])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 398])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 199])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 100])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 50])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 50])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 6400])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 398])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 398])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 199])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 100])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 50])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 50])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 6400])

[Processing Pair 70/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2098/00071.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2098/00071.wav
Generated Mel Shape: torch.Size([1, 128, 262]), Reference Mel Shape: torch.Size([1, 128, 281])
Generated Mel Shape: torch.Size([1, 128, 262]), Reference Mel Shape: torch.Size([1, 128, 262])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 262])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 262])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 33])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4224])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 262])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 262])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 33])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4224])

[Processing Pair 71/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2117/00018.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2117/00018.wav
Generated Mel Shape: torch.Size([1, 128, 294]), Reference Mel Shape: torch.Size([1, 128, 262])
Generated Mel Shape: torch.Size([1, 128, 262]), Reference Mel Shape: torch.Size([1, 128, 262])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 262])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 262])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 33])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4224])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 262])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 262])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 33])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4224])

[Processing Pair 72/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2200/00018.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2200/00018.wav
Generated Mel Shape: torch.Size([1, 128, 155]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 155]), Reference Mel Shape: torch.Size([1, 128, 155])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 155])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 155])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 78])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 155])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 155])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 78])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 73/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2200/00031.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2200/00031.wav
Generated Mel Shape: torch.Size([1, 128, 197]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 197]), Reference Mel Shape: torch.Size([1, 128, 197])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 197])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 197])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 99])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 197])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 197])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 99])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])

[Processing Pair 74/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2200/00042.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2200/00042.wav
Generated Mel Shape: torch.Size([1, 128, 134]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 134]), Reference Mel Shape: torch.Size([1, 128, 134])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 75/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2260/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2260/00002.wav
Generated Mel Shape: torch.Size([1, 128, 301]), Reference Mel Shape: torch.Size([1, 128, 441])
Generated Mel Shape: torch.Size([1, 128, 301]), Reference Mel Shape: torch.Size([1, 128, 301])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 301])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 301])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 151])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 38])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4864])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 301])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 301])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 151])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 38])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4864])

[Processing Pair 76/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2403/00024.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2403/00024.wav
Generated Mel Shape: torch.Size([1, 128, 171]), Reference Mel Shape: torch.Size([1, 128, 326])
Generated Mel Shape: torch.Size([1, 128, 171]), Reference Mel Shape: torch.Size([1, 128, 171])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 171])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 171])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 171])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 171])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 77/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2403/00025.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2403/00025.wav
Generated Mel Shape: torch.Size([1, 128, 171]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 171]), Reference Mel Shape: torch.Size([1, 128, 171])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 171])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 171])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 171])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 171])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 78/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2403/00030.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2403/00030.wav
Generated Mel Shape: torch.Size([1, 128, 192]), Reference Mel Shape: torch.Size([1, 128, 236])
Generated Mel Shape: torch.Size([1, 128, 192]), Reference Mel Shape: torch.Size([1, 128, 192])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 192])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 192])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 192])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 192])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 79/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2403/00041.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2403/00041.wav
Generated Mel Shape: torch.Size([1, 128, 234]), Reference Mel Shape: torch.Size([1, 128, 262])
Generated Mel Shape: torch.Size([1, 128, 234]), Reference Mel Shape: torch.Size([1, 128, 234])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 234])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 234])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 30])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3840])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 234])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 234])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 30])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3840])

[Processing Pair 80/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2404/00005.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2404/00005.wav
Generated Mel Shape: torch.Size([1, 128, 119]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 119]), Reference Mel Shape: torch.Size([1, 128, 119])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 119])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 119])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 119])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 119])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 81/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2404/00029.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2404/00029.wav
Generated Mel Shape: torch.Size([1, 128, 111]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 111]), Reference Mel Shape: torch.Size([1, 128, 111])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 111])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 111])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 111])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 111])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 82/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2414/00017.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2414/00017.wav
Generated Mel Shape: torch.Size([1, 128, 174]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 174]), Reference Mel Shape: torch.Size([1, 128, 174])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 174])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 174])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 87])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 174])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 174])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 87])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 83/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2431/00003.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2431/00003.wav
Generated Mel Shape: torch.Size([1, 128, 171]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 166]), Reference Mel Shape: torch.Size([1, 128, 166])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 166])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 166])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 84/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2474/00051.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2474/00051.wav
Generated Mel Shape: torch.Size([1, 128, 182]), Reference Mel Shape: torch.Size([1, 128, 236])
Generated Mel Shape: torch.Size([1, 128, 182]), Reference Mel Shape: torch.Size([1, 128, 182])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 182])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 182])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 91])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 182])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 182])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 91])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 85/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2482/00005.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2482/00005.wav
Generated Mel Shape: torch.Size([1, 128, 156]), Reference Mel Shape: torch.Size([1, 128, 198])
Generated Mel Shape: torch.Size([1, 128, 156]), Reference Mel Shape: torch.Size([1, 128, 156])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 156])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 156])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 78])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 156])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 156])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 78])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 86/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2500/00003.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2500/00003.wav
Generated Mel Shape: torch.Size([1, 128, 142]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 142]), Reference Mel Shape: torch.Size([1, 128, 142])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 142])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 142])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 142])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 142])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 87/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2500/00008.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2500/00008.wav
Generated Mel Shape: torch.Size([1, 128, 117]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 117]), Reference Mel Shape: torch.Size([1, 128, 117])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 117])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 117])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 88/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2506/00050.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2506/00050.wav
Generated Mel Shape: torch.Size([1, 128, 126]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 126]), Reference Mel Shape: torch.Size([1, 128, 126])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 126])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 126])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 63])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 126])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 126])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 63])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 89/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2506/00051.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2506/00051.wav
Generated Mel Shape: torch.Size([1, 128, 364]), Reference Mel Shape: torch.Size([1, 128, 358])
Generated Mel Shape: torch.Size([1, 128, 358]), Reference Mel Shape: torch.Size([1, 128, 358])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 358])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 358])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 179])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 45])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5760])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 358])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 358])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 179])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 45])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5760])

[Processing Pair 90/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2520/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2520/00002.wav
Generated Mel Shape: torch.Size([1, 128, 166]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 166]), Reference Mel Shape: torch.Size([1, 128, 166])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 166])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 166])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 91/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2555/00017.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2555/00017.wav
Generated Mel Shape: torch.Size([1, 128, 202]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 202]), Reference Mel Shape: torch.Size([1, 128, 202])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 202])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 202])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 202])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 202])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])

[Processing Pair 92/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2555/00019.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2555/00019.wav
Generated Mel Shape: torch.Size([1, 128, 124]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 124]), Reference Mel Shape: torch.Size([1, 128, 124])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 124])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 124])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 62])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 124])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 124])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 62])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 93/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2555/00029.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2555/00029.wav
Generated Mel Shape: torch.Size([1, 128, 126]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 126]), Reference Mel Shape: torch.Size([1, 128, 126])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 126])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 126])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 63])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 126])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 126])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 63])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 94/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2555/00055.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2555/00055.wav
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 95/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2555/00061.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2555/00061.wav
Generated Mel Shape: torch.Size([1, 128, 129]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 129]), Reference Mel Shape: torch.Size([1, 128, 129])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 129])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 129])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 129])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 129])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 96/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2555/00067.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2555/00067.wav
Generated Mel Shape: torch.Size([1, 128, 171]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 171]), Reference Mel Shape: torch.Size([1, 128, 171])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 171])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 171])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 171])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 171])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 97/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2555/00068.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2555/00068.wav
Generated Mel Shape: torch.Size([1, 128, 117]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 117]), Reference Mel Shape: torch.Size([1, 128, 117])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 117])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 117])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 98/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2555/00069.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2555/00069.wav
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 99/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2565/00030.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2565/00030.wav
Generated Mel Shape: torch.Size([1, 128, 334]), Reference Mel Shape: torch.Size([1, 128, 352])
Generated Mel Shape: torch.Size([1, 128, 334]), Reference Mel Shape: torch.Size([1, 128, 334])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 334])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 334])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 167])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 84])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 42])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 42])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5376])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 334])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 334])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 167])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 84])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 42])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 42])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5376])

[Processing Pair 100/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2650/00017.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2650/00017.wav
Generated Mel Shape: torch.Size([1, 128, 166]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 166]), Reference Mel Shape: torch.Size([1, 128, 166])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 166])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 166])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 101/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2650/00024.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2650/00024.wav
Generated Mel Shape: torch.Size([1, 128, 306]), Reference Mel Shape: torch.Size([1, 128, 313])
Generated Mel Shape: torch.Size([1, 128, 306]), Reference Mel Shape: torch.Size([1, 128, 306])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 306])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 306])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 39])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 39])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4992])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 306])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 306])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 39])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 39])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4992])

[Processing Pair 102/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2650/00039.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2650/00039.wav
Generated Mel Shape: torch.Size([1, 128, 160]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 160]), Reference Mel Shape: torch.Size([1, 128, 160])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 103/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2662/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2662/00002.wav
Generated Mel Shape: torch.Size([1, 128, 113]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 113]), Reference Mel Shape: torch.Size([1, 128, 113])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 113])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 113])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 113])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 113])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 104/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2689/00026.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2689/00026.wav
Generated Mel Shape: torch.Size([1, 128, 132]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 132]), Reference Mel Shape: torch.Size([1, 128, 132])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 132])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 132])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 132])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 132])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 105/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2711/00001.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2711/00001.wav
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 131])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 106/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2757/00027.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2757/00027.wav
Generated Mel Shape: torch.Size([1, 128, 202]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 185]), Reference Mel Shape: torch.Size([1, 128, 185])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 185])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 185])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 93])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 185])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 185])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 93])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 107/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2771/00001.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2771/00001.wav
Generated Mel Shape: torch.Size([1, 128, 182]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 182]), Reference Mel Shape: torch.Size([1, 128, 182])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 182])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 182])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 91])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 182])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 182])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 91])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 108/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2771/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2771/00002.wav
Generated Mel Shape: torch.Size([1, 128, 112]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 112]), Reference Mel Shape: torch.Size([1, 128, 112])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 112])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 112])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 109/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2771/00051.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2771/00051.wav
Generated Mel Shape: torch.Size([1, 128, 228]), Reference Mel Shape: torch.Size([1, 128, 211])
Generated Mel Shape: torch.Size([1, 128, 211]), Reference Mel Shape: torch.Size([1, 128, 211])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 211])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 211])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 106])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 211])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 211])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 106])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])

[Processing Pair 110/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2771/00055.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2771/00055.wav
Generated Mel Shape: torch.Size([1, 128, 113]), Reference Mel Shape: torch.Size([1, 128, 134])
Generated Mel Shape: torch.Size([1, 128, 113]), Reference Mel Shape: torch.Size([1, 128, 113])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 113])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 113])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 113])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 113])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 111/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2771/00057.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2771/00057.wav
Generated Mel Shape: torch.Size([1, 128, 175]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 175]), Reference Mel Shape: torch.Size([1, 128, 175])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 175])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 175])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 88])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 175])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 175])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 88])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 112/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2771/00082.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2771/00082.wav
Generated Mel Shape: torch.Size([1, 128, 202]), Reference Mel Shape: torch.Size([1, 128, 249])
Generated Mel Shape: torch.Size([1, 128, 202]), Reference Mel Shape: torch.Size([1, 128, 202])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 202])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 202])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 202])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 202])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])

[Processing Pair 113/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2771/00105.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2771/00105.wav
Generated Mel Shape: torch.Size([1, 128, 103]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 103]), Reference Mel Shape: torch.Size([1, 128, 103])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 103])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 103])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 103])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 103])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])

[Processing Pair 114/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2771/00134.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2771/00134.wav
Generated Mel Shape: torch.Size([1, 128, 357]), Reference Mel Shape: torch.Size([1, 128, 377])
Generated Mel Shape: torch.Size([1, 128, 357]), Reference Mel Shape: torch.Size([1, 128, 357])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 357])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 357])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 179])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 45])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5760])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 357])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 357])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 179])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 45])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5760])

[Processing Pair 115/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2771/00138.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2771/00138.wav
Generated Mel Shape: torch.Size([1, 128, 192]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 192]), Reference Mel Shape: torch.Size([1, 128, 192])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 192])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 192])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 192])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 192])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 116/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2771/00153.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2771/00153.wav
Generated Mel Shape: torch.Size([1, 128, 196]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 196]), Reference Mel Shape: torch.Size([1, 128, 196])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 196])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 196])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 98])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 49])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 196])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 196])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 98])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 49])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])

[Processing Pair 117/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2771/00193.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2771/00193.wav
Generated Mel Shape: torch.Size([1, 128, 156]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 118/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2771/00196.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2771/00196.wav
Generated Mel Shape: torch.Size([1, 128, 98]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 98]), Reference Mel Shape: torch.Size([1, 128, 98])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 98])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 98])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 49])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 98])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 98])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 49])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])

[Processing Pair 119/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2771/00207.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2771/00207.wav
Generated Mel Shape: torch.Size([1, 128, 167]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 160]), Reference Mel Shape: torch.Size([1, 128, 160])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 120/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2872/00047.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2872/00047.wav
Generated Mel Shape: torch.Size([1, 128, 108]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 108]), Reference Mel Shape: torch.Size([1, 128, 108])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 108])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 108])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 108])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 108])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 121/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2872/00048.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2872/00048.wav
Generated Mel Shape: torch.Size([1, 128, 192]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 172]), Reference Mel Shape: torch.Size([1, 128, 172])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 122/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2930/00014.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2930/00014.wav
Generated Mel Shape: torch.Size([1, 128, 145]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 145]), Reference Mel Shape: torch.Size([1, 128, 145])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 145])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 145])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 145])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 145])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 123/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2979/00014.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2979/00014.wav
Generated Mel Shape: torch.Size([1, 128, 89]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 89]), Reference Mel Shape: torch.Size([1, 128, 89])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 89])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 89])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])

[Processing Pair 124/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk2986/00065.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk2986/00065.wav
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 131])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 125/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3013/00001.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3013/00001.wav
Generated Mel Shape: torch.Size([1, 128, 264]), Reference Mel Shape: torch.Size([1, 128, 249])
Generated Mel Shape: torch.Size([1, 128, 249]), Reference Mel Shape: torch.Size([1, 128, 249])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 249])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 249])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 125])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 63])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 249])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 249])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 125])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 63])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])

[Processing Pair 126/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3013/00004.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3013/00004.wav
Generated Mel Shape: torch.Size([1, 128, 353]), Reference Mel Shape: torch.Size([1, 128, 377])
Generated Mel Shape: torch.Size([1, 128, 353]), Reference Mel Shape: torch.Size([1, 128, 353])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 353])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 353])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 177])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 45])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5760])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 353])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 353])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 177])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 45])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5760])

[Processing Pair 127/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3013/00005.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3013/00005.wav
Generated Mel Shape: torch.Size([1, 128, 307]), Reference Mel Shape: torch.Size([1, 128, 332])
Generated Mel Shape: torch.Size([1, 128, 307]), Reference Mel Shape: torch.Size([1, 128, 307])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 307])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 307])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 154])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 39])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 39])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4992])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 307])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 307])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 154])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 39])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 39])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4992])

[Processing Pair 128/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3013/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3013/00006.wav
Generated Mel Shape: torch.Size([1, 128, 84]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 84]), Reference Mel Shape: torch.Size([1, 128, 84])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 84])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 84])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 11])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1408])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 84])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 84])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 11])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1408])

[Processing Pair 129/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3013/00008.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3013/00008.wav
Generated Mel Shape: torch.Size([1, 128, 280]), Reference Mel Shape: torch.Size([1, 128, 332])
Generated Mel Shape: torch.Size([1, 128, 280]), Reference Mel Shape: torch.Size([1, 128, 280])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 280])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 280])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 35])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4480])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 280])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 280])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 35])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4480])

[Processing Pair 130/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3013/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3013/00011.wav
Generated Mel Shape: torch.Size([1, 128, 182]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 172]), Reference Mel Shape: torch.Size([1, 128, 172])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 131/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3013/00012.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3013/00012.wav
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 161])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 161])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 161])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 161])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 161])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 132/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3013/00013.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3013/00013.wav
Generated Mel Shape: torch.Size([1, 128, 182]), Reference Mel Shape: torch.Size([1, 128, 217])
Generated Mel Shape: torch.Size([1, 128, 182]), Reference Mel Shape: torch.Size([1, 128, 182])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 182])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 182])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 91])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 182])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 182])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 91])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 133/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3013/00014.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3013/00014.wav
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 134/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3013/00015.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3013/00015.wav
Generated Mel Shape: torch.Size([1, 128, 180]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 172]), Reference Mel Shape: torch.Size([1, 128, 172])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 135/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3013/00017.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3013/00017.wav
Generated Mel Shape: torch.Size([1, 128, 222]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 204]), Reference Mel Shape: torch.Size([1, 128, 204])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 204])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 204])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 204])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 204])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])

[Processing Pair 136/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3013/00019.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3013/00019.wav
Generated Mel Shape: torch.Size([1, 128, 299]), Reference Mel Shape: torch.Size([1, 128, 281])
Generated Mel Shape: torch.Size([1, 128, 281]), Reference Mel Shape: torch.Size([1, 128, 281])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 281])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 281])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 36])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 36])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4608])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 281])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 281])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 36])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 36])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4608])

[Processing Pair 137/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3013/00023.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3013/00023.wav
Generated Mel Shape: torch.Size([1, 128, 145]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 145]), Reference Mel Shape: torch.Size([1, 128, 145])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 145])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 145])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 145])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 145])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 138/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3013/00025.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3013/00025.wav
Generated Mel Shape: torch.Size([1, 128, 289]), Reference Mel Shape: torch.Size([1, 128, 377])
Generated Mel Shape: torch.Size([1, 128, 289]), Reference Mel Shape: torch.Size([1, 128, 289])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 289])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 289])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 145])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 37])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 37])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4736])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 289])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 289])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 145])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 37])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 37])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4736])

[Processing Pair 139/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3013/00035.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3013/00035.wav
Generated Mel Shape: torch.Size([1, 128, 168]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 168]), Reference Mel Shape: torch.Size([1, 128, 168])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 168])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 168])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 84])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 168])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 168])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 84])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 140/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3013/00036.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3013/00036.wav
Generated Mel Shape: torch.Size([1, 128, 226]), Reference Mel Shape: torch.Size([1, 128, 211])
Generated Mel Shape: torch.Size([1, 128, 211]), Reference Mel Shape: torch.Size([1, 128, 211])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 211])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 211])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 106])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 211])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 211])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 106])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])

[Processing Pair 141/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3013/00046.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3013/00046.wav
Generated Mel Shape: torch.Size([1, 128, 212]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 212]), Reference Mel Shape: torch.Size([1, 128, 212])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 212])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 212])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 106])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 212])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 212])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 106])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])

[Processing Pair 142/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3013/00053.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3013/00053.wav
Generated Mel Shape: torch.Size([1, 128, 116]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 116]), Reference Mel Shape: torch.Size([1, 128, 116])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 116])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 116])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 143/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3067/00003.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3067/00003.wav
Generated Mel Shape: torch.Size([1, 128, 214]), Reference Mel Shape: torch.Size([1, 128, 230])
Generated Mel Shape: torch.Size([1, 128, 214]), Reference Mel Shape: torch.Size([1, 128, 214])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 214])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 214])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 107])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 214])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 214])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 107])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])

[Processing Pair 144/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk315/00005.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk315/00005.wav
Generated Mel Shape: torch.Size([1, 128, 119]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 119]), Reference Mel Shape: torch.Size([1, 128, 119])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 119])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 119])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 119])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 119])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 145/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3260/00008.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3260/00008.wav
Generated Mel Shape: torch.Size([1, 128, 145]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 145]), Reference Mel Shape: torch.Size([1, 128, 145])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 145])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 145])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 145])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 145])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 146/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3260/00051.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3260/00051.wav
Generated Mel Shape: torch.Size([1, 128, 113]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 113]), Reference Mel Shape: torch.Size([1, 128, 113])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 113])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 113])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 113])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 113])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 147/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3260/00073.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3260/00073.wav
Generated Mel Shape: torch.Size([1, 128, 205]), Reference Mel Shape: torch.Size([1, 128, 230])
Generated Mel Shape: torch.Size([1, 128, 205]), Reference Mel Shape: torch.Size([1, 128, 205])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 205])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 205])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 103])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 205])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 205])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 103])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])

[Processing Pair 148/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3260/00111.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3260/00111.wav
Generated Mel Shape: torch.Size([1, 128, 113]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 113]), Reference Mel Shape: torch.Size([1, 128, 113])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 113])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 113])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 113])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 113])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 149/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3260/00113.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3260/00113.wav
Generated Mel Shape: torch.Size([1, 128, 109]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 109]), Reference Mel Shape: torch.Size([1, 128, 109])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 109])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 109])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 55])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 109])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 109])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 55])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 150/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3265/00023.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3265/00023.wav
Generated Mel Shape: torch.Size([1, 128, 166]), Reference Mel Shape: torch.Size([1, 128, 243])
Generated Mel Shape: torch.Size([1, 128, 166]), Reference Mel Shape: torch.Size([1, 128, 166])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 166])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 166])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 151/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3291/00020.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3291/00020.wav
Generated Mel Shape: torch.Size([1, 128, 256]), Reference Mel Shape: torch.Size([1, 128, 352])
Generated Mel Shape: torch.Size([1, 128, 256]), Reference Mel Shape: torch.Size([1, 128, 256])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 256])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 256])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 256])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 256])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])

[Processing Pair 152/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3291/00050.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3291/00050.wav
Generated Mel Shape: torch.Size([1, 128, 176]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 172]), Reference Mel Shape: torch.Size([1, 128, 172])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 153/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3291/00052.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3291/00052.wav
Generated Mel Shape: torch.Size([1, 128, 181]), Reference Mel Shape: torch.Size([1, 128, 217])
Generated Mel Shape: torch.Size([1, 128, 181]), Reference Mel Shape: torch.Size([1, 128, 181])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 181])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 181])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 91])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 181])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 181])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 91])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 154/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3367/00008.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3367/00008.wav
Generated Mel Shape: torch.Size([1, 128, 174]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 174]), Reference Mel Shape: torch.Size([1, 128, 174])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 174])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 174])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 87])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 174])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 174])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 87])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 155/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3367/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3367/00011.wav
Generated Mel Shape: torch.Size([1, 128, 270]), Reference Mel Shape: torch.Size([1, 128, 300])
Generated Mel Shape: torch.Size([1, 128, 270]), Reference Mel Shape: torch.Size([1, 128, 270])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 270])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 270])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 135])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 68])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 34])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 34])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4352])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 270])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 270])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 135])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 68])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 34])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 34])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4352])

[Processing Pair 156/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3367/00012.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3367/00012.wav
Generated Mel Shape: torch.Size([1, 128, 163]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 163]), Reference Mel Shape: torch.Size([1, 128, 163])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 163])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 163])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 163])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 163])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 157/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3420/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3420/00011.wav
Generated Mel Shape: torch.Size([1, 128, 354]), Reference Mel Shape: torch.Size([1, 128, 396])
Generated Mel Shape: torch.Size([1, 128, 354]), Reference Mel Shape: torch.Size([1, 128, 354])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 354])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 354])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 177])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 45])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5760])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 354])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 354])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 177])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 45])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5760])

[Processing Pair 158/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3423/00048.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3423/00048.wav
Generated Mel Shape: torch.Size([1, 128, 210]), Reference Mel Shape: torch.Size([1, 128, 236])
Generated Mel Shape: torch.Size([1, 128, 210]), Reference Mel Shape: torch.Size([1, 128, 210])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 210])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 210])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 105])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 210])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 210])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 105])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])

[Processing Pair 159/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3458/00001.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3458/00001.wav
Generated Mel Shape: torch.Size([1, 128, 112]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 112]), Reference Mel Shape: torch.Size([1, 128, 112])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 112])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 112])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 160/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk352/00016.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk352/00016.wav
Generated Mel Shape: torch.Size([1, 128, 213]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 192]), Reference Mel Shape: torch.Size([1, 128, 192])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 192])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 192])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 192])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 192])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 161/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3654/00037.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3654/00037.wav
Generated Mel Shape: torch.Size([1, 128, 117]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 117]), Reference Mel Shape: torch.Size([1, 128, 117])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 117])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 117])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 162/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk3995/00014.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk3995/00014.wav
Generated Mel Shape: torch.Size([1, 128, 135]), Reference Mel Shape: torch.Size([1, 128, 134])
Generated Mel Shape: torch.Size([1, 128, 134]), Reference Mel Shape: torch.Size([1, 128, 134])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 163/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4099/00016.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4099/00016.wav
Generated Mel Shape: torch.Size([1, 128, 114]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 114]), Reference Mel Shape: torch.Size([1, 128, 114])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 114])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 114])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 114])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 114])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 164/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk41/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk41/00006.wav
Generated Mel Shape: torch.Size([1, 128, 225]), Reference Mel Shape: torch.Size([1, 128, 256])
Generated Mel Shape: torch.Size([1, 128, 225]), Reference Mel Shape: torch.Size([1, 128, 225])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 225])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 225])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 113])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 225])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 225])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 113])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])

[Processing Pair 165/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk41/00010.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk41/00010.wav
Generated Mel Shape: torch.Size([1, 128, 218]), Reference Mel Shape: torch.Size([1, 128, 236])
Generated Mel Shape: torch.Size([1, 128, 218]), Reference Mel Shape: torch.Size([1, 128, 218])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 218])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 218])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 109])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 55])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 218])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 218])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 109])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 55])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])

[Processing Pair 166/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk41/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk41/00011.wav
Generated Mel Shape: torch.Size([1, 128, 232]), Reference Mel Shape: torch.Size([1, 128, 281])
Generated Mel Shape: torch.Size([1, 128, 232]), Reference Mel Shape: torch.Size([1, 128, 232])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 232])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 232])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 232])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 232])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])

[Processing Pair 167/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk410/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk410/00002.wav
Generated Mel Shape: torch.Size([1, 128, 73]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 73]), Reference Mel Shape: torch.Size([1, 128, 73])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 73])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 10])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 10])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 10])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1280])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 73])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 10])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 10])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 10])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1280])

[Processing Pair 168/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4171/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4171/00002.wav
Generated Mel Shape: torch.Size([1, 128, 123]), Reference Mel Shape: torch.Size([1, 128, 236])
Generated Mel Shape: torch.Size([1, 128, 123]), Reference Mel Shape: torch.Size([1, 128, 123])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 123])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 123])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 62])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 123])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 123])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 62])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 169/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4171/00058.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4171/00058.wav
Generated Mel Shape: torch.Size([1, 128, 120]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 120]), Reference Mel Shape: torch.Size([1, 128, 120])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 120])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 120])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 120])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 120])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 170/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4171/00059.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4171/00059.wav
Generated Mel Shape: torch.Size([1, 128, 148]), Reference Mel Shape: torch.Size([1, 128, 249])
Generated Mel Shape: torch.Size([1, 128, 148]), Reference Mel Shape: torch.Size([1, 128, 148])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 148])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 148])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 148])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 148])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 171/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4171/00073.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4171/00073.wav
Generated Mel Shape: torch.Size([1, 128, 101]), Reference Mel Shape: torch.Size([1, 128, 217])
Generated Mel Shape: torch.Size([1, 128, 101]), Reference Mel Shape: torch.Size([1, 128, 101])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 101])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 101])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])

[Processing Pair 172/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4171/00082.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4171/00082.wav
Generated Mel Shape: torch.Size([1, 128, 294]), Reference Mel Shape: torch.Size([1, 128, 364])
Generated Mel Shape: torch.Size([1, 128, 294]), Reference Mel Shape: torch.Size([1, 128, 294])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 294])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 294])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 37])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 37])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4736])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 294])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 294])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 37])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 37])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4736])

[Processing Pair 173/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk423/00001.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk423/00001.wav
Generated Mel Shape: torch.Size([1, 128, 114]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 114]), Reference Mel Shape: torch.Size([1, 128, 114])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 114])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 114])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 114])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 114])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 174/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk423/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk423/00002.wav
Generated Mel Shape: torch.Size([1, 128, 187]), Reference Mel Shape: torch.Size([1, 128, 198])
Generated Mel Shape: torch.Size([1, 128, 187]), Reference Mel Shape: torch.Size([1, 128, 187])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 187])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 187])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 94])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 187])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 187])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 94])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 175/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk423/00003.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk423/00003.wav
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 161])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 161])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 161])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 161])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 161])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 176/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk423/00004.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk423/00004.wav
Generated Mel Shape: torch.Size([1, 128, 165]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 165]), Reference Mel Shape: torch.Size([1, 128, 165])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 165])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 165])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 165])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 165])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 177/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk423/00005.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk423/00005.wav
Generated Mel Shape: torch.Size([1, 128, 101]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 101]), Reference Mel Shape: torch.Size([1, 128, 101])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 101])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 101])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])

[Processing Pair 178/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk423/00016.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk423/00016.wav
Generated Mel Shape: torch.Size([1, 128, 170]), Reference Mel Shape: torch.Size([1, 128, 198])
Generated Mel Shape: torch.Size([1, 128, 170]), Reference Mel Shape: torch.Size([1, 128, 170])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 170])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 170])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 85])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 170])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 170])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 85])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 179/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4236/00010.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4236/00010.wav
Generated Mel Shape: torch.Size([1, 128, 198]), Reference Mel Shape: torch.Size([1, 128, 217])
Generated Mel Shape: torch.Size([1, 128, 198]), Reference Mel Shape: torch.Size([1, 128, 198])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 198])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 198])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 99])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 198])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 198])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 99])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])

[Processing Pair 180/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4249/00015.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4249/00015.wav
Generated Mel Shape: torch.Size([1, 128, 249]), Reference Mel Shape: torch.Size([1, 128, 288])
Generated Mel Shape: torch.Size([1, 128, 249]), Reference Mel Shape: torch.Size([1, 128, 249])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 249])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 249])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 125])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 63])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 249])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 249])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 125])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 63])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])

[Processing Pair 181/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4268/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4268/00006.wav
Generated Mel Shape: torch.Size([1, 128, 332]), Reference Mel Shape: torch.Size([1, 128, 384])
Generated Mel Shape: torch.Size([1, 128, 332]), Reference Mel Shape: torch.Size([1, 128, 332])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 332])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 332])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 42])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 42])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5376])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 332])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 332])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 42])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 42])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5376])

[Processing Pair 182/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4276/00004.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4276/00004.wav
Generated Mel Shape: torch.Size([1, 128, 113]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 113]), Reference Mel Shape: torch.Size([1, 128, 113])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 113])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 113])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 113])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 113])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 183/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4277/00005.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4277/00005.wav
Generated Mel Shape: torch.Size([1, 128, 132]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 132]), Reference Mel Shape: torch.Size([1, 128, 132])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 132])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 132])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 132])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 132])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 184/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4393/00015.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4393/00015.wav
Generated Mel Shape: torch.Size([1, 128, 110]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 110]), Reference Mel Shape: torch.Size([1, 128, 110])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 110])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 110])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 55])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 110])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 110])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 55])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 185/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk44/00003.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk44/00003.wav
Generated Mel Shape: torch.Size([1, 128, 90]), Reference Mel Shape: torch.Size([1, 128, 134])
Generated Mel Shape: torch.Size([1, 128, 90]), Reference Mel Shape: torch.Size([1, 128, 90])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 90])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 90])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])

[Processing Pair 186/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk44/00010.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk44/00010.wav
Generated Mel Shape: torch.Size([1, 128, 134]), Reference Mel Shape: torch.Size([1, 128, 211])
Generated Mel Shape: torch.Size([1, 128, 134]), Reference Mel Shape: torch.Size([1, 128, 134])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 187/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk44/00025.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk44/00025.wav
Generated Mel Shape: torch.Size([1, 128, 129]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 129]), Reference Mel Shape: torch.Size([1, 128, 129])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 129])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 129])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 129])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 129])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 188/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk443/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk443/00006.wav
Generated Mel Shape: torch.Size([1, 128, 151]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 151]), Reference Mel Shape: torch.Size([1, 128, 151])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 151])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 151])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 151])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 151])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 189/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk446/00022.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk446/00022.wav
Generated Mel Shape: torch.Size([1, 128, 123]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 123]), Reference Mel Shape: torch.Size([1, 128, 123])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 123])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 123])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 62])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 123])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 123])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 62])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 190/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4476/00028.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4476/00028.wav
Generated Mel Shape: torch.Size([1, 128, 201]), Reference Mel Shape: torch.Size([1, 128, 256])
Generated Mel Shape: torch.Size([1, 128, 201]), Reference Mel Shape: torch.Size([1, 128, 201])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 201])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 201])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 201])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 201])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])

[Processing Pair 191/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4491/00146.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4491/00146.wav
Generated Mel Shape: torch.Size([1, 128, 108]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 108]), Reference Mel Shape: torch.Size([1, 128, 108])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 108])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 108])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 108])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 108])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 192/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4552/00010.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4552/00010.wav
Generated Mel Shape: torch.Size([1, 128, 179]), Reference Mel Shape: torch.Size([1, 128, 249])
Generated Mel Shape: torch.Size([1, 128, 179]), Reference Mel Shape: torch.Size([1, 128, 179])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 179])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 179])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 179])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 179])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 193/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4575/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4575/00002.wav
Generated Mel Shape: torch.Size([1, 128, 157]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 157]), Reference Mel Shape: torch.Size([1, 128, 157])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 157])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 157])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 79])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 157])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 157])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 79])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 194/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4576/00012.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4576/00012.wav
Generated Mel Shape: torch.Size([1, 128, 119]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 119]), Reference Mel Shape: torch.Size([1, 128, 119])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 119])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 119])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 119])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 119])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 195/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4577/00051.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4577/00051.wav
Generated Mel Shape: torch.Size([1, 128, 243]), Reference Mel Shape: torch.Size([1, 128, 320])
Generated Mel Shape: torch.Size([1, 128, 243]), Reference Mel Shape: torch.Size([1, 128, 243])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 243])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 243])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 122])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 31])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 31])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3968])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 243])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 243])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 122])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 31])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 31])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3968])

[Processing Pair 196/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4579/00015.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4579/00015.wav
Generated Mel Shape: torch.Size([1, 128, 121]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 121]), Reference Mel Shape: torch.Size([1, 128, 121])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 121])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 121])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 121])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 121])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 197/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4652/00060.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4652/00060.wav
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 198/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4652/00089.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4652/00089.wav
Generated Mel Shape: torch.Size([1, 128, 281]), Reference Mel Shape: torch.Size([1, 128, 384])
Generated Mel Shape: torch.Size([1, 128, 281]), Reference Mel Shape: torch.Size([1, 128, 281])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 281])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 281])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 36])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 36])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4608])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 281])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 281])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 36])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 36])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4608])

[Processing Pair 199/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4661/00038.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4661/00038.wav
Generated Mel Shape: torch.Size([1, 128, 293]), Reference Mel Shape: torch.Size([1, 128, 326])
Generated Mel Shape: torch.Size([1, 128, 293]), Reference Mel Shape: torch.Size([1, 128, 293])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 293])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 293])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 37])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 37])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4736])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 293])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 293])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 37])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 37])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4736])

[Processing Pair 200/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4663/00103.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4663/00103.wav
Generated Mel Shape: torch.Size([1, 128, 360]), Reference Mel Shape: torch.Size([1, 128, 582])
Generated Mel Shape: torch.Size([1, 128, 360]), Reference Mel Shape: torch.Size([1, 128, 360])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 360])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 360])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 180])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 45])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5760])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 360])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 360])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 180])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 45])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5760])

[Processing Pair 201/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4718/00020.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4718/00020.wav
Generated Mel Shape: torch.Size([1, 128, 166]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 202/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4763/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4763/00006.wav
Generated Mel Shape: torch.Size([1, 128, 117]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 117]), Reference Mel Shape: torch.Size([1, 128, 117])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 117])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 117])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 203/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4763/00014.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4763/00014.wav
Generated Mel Shape: torch.Size([1, 128, 133]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 133]), Reference Mel Shape: torch.Size([1, 128, 133])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 133])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 133])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 133])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 133])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 204/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4763/00015.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4763/00015.wav
Generated Mel Shape: torch.Size([1, 128, 154]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 154]), Reference Mel Shape: torch.Size([1, 128, 154])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 154])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 154])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 154])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 154])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 205/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4846/00007.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4846/00007.wav
Generated Mel Shape: torch.Size([1, 128, 120]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 120]), Reference Mel Shape: torch.Size([1, 128, 120])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 120])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 120])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 120])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 120])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 206/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4851/00013.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4851/00013.wav
Generated Mel Shape: torch.Size([1, 128, 116]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 116]), Reference Mel Shape: torch.Size([1, 128, 116])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 116])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 116])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 207/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4864/00001.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4864/00001.wav
Generated Mel Shape: torch.Size([1, 128, 110]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 110]), Reference Mel Shape: torch.Size([1, 128, 110])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 110])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 110])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 55])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 110])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 110])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 55])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 208/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4864/00010.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4864/00010.wav
Generated Mel Shape: torch.Size([1, 128, 298]), Reference Mel Shape: torch.Size([1, 128, 281])
Generated Mel Shape: torch.Size([1, 128, 281]), Reference Mel Shape: torch.Size([1, 128, 281])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 281])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 281])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 36])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 36])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4608])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 281])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 281])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 36])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 36])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4608])

[Processing Pair 209/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4864/00027.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4864/00027.wav
Generated Mel Shape: torch.Size([1, 128, 118]), Reference Mel Shape: torch.Size([1, 128, 198])
Generated Mel Shape: torch.Size([1, 128, 118]), Reference Mel Shape: torch.Size([1, 128, 118])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 118])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 118])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 118])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 118])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 210/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk488/00037.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk488/00037.wav
Generated Mel Shape: torch.Size([1, 128, 167]), Reference Mel Shape: torch.Size([1, 128, 198])
Generated Mel Shape: torch.Size([1, 128, 167]), Reference Mel Shape: torch.Size([1, 128, 167])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 167])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 167])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 84])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 167])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 167])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 84])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 211/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4896/00004.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4896/00004.wav
Generated Mel Shape: torch.Size([1, 128, 119]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 119]), Reference Mel Shape: torch.Size([1, 128, 119])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 119])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 119])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 119])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 119])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 212/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4896/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4896/00011.wav
Generated Mel Shape: torch.Size([1, 128, 117]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 117]), Reference Mel Shape: torch.Size([1, 128, 117])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 117])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 117])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 213/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4945/00001.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4945/00001.wav
Generated Mel Shape: torch.Size([1, 128, 278]), Reference Mel Shape: torch.Size([1, 128, 256])
Generated Mel Shape: torch.Size([1, 128, 256]), Reference Mel Shape: torch.Size([1, 128, 256])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 256])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 256])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 256])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 256])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])

[Processing Pair 214/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk4958/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk4958/00006.wav
Generated Mel Shape: torch.Size([1, 128, 265]), Reference Mel Shape: torch.Size([1, 128, 236])
Generated Mel Shape: torch.Size([1, 128, 236]), Reference Mel Shape: torch.Size([1, 128, 236])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 236])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 236])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 118])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 30])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3840])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 236])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 236])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 118])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 30])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3840])

[Processing Pair 215/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5134/00017.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5134/00017.wav
Generated Mel Shape: torch.Size([1, 128, 176]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 166]), Reference Mel Shape: torch.Size([1, 128, 166])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 166])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 166])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 216/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5170/00028.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5170/00028.wav
Generated Mel Shape: torch.Size([1, 128, 157]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 157]), Reference Mel Shape: torch.Size([1, 128, 157])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 157])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 157])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 79])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 157])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 157])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 79])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 217/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5210/00013.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5210/00013.wav
Generated Mel Shape: torch.Size([1, 128, 103]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 103]), Reference Mel Shape: torch.Size([1, 128, 103])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 103])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 103])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 103])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 103])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])

[Processing Pair 218/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5210/00017.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5210/00017.wav
Generated Mel Shape: torch.Size([1, 128, 144]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 144]), Reference Mel Shape: torch.Size([1, 128, 144])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 144])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 144])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 144])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 144])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 219/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5210/00022.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5210/00022.wav
Generated Mel Shape: torch.Size([1, 128, 89]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 89]), Reference Mel Shape: torch.Size([1, 128, 89])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 89])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 89])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])

[Processing Pair 220/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5210/00171.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5210/00171.wav
Generated Mel Shape: torch.Size([1, 128, 115]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 115]), Reference Mel Shape: torch.Size([1, 128, 115])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 115])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 115])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 115])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 115])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 221/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5295/00043.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5295/00043.wav
Generated Mel Shape: torch.Size([1, 128, 91]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 91]), Reference Mel Shape: torch.Size([1, 128, 91])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 91])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 91])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 91])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 91])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])

[Processing Pair 222/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5386/00009.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5386/00009.wav
Generated Mel Shape: torch.Size([1, 128, 356]), Reference Mel Shape: torch.Size([1, 128, 377])
Generated Mel Shape: torch.Size([1, 128, 356]), Reference Mel Shape: torch.Size([1, 128, 356])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 356])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 356])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 178])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 45])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5760])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 356])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 356])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 178])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 45])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5760])

[Processing Pair 223/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5454/00019.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5454/00019.wav
Generated Mel Shape: torch.Size([1, 128, 150]), Reference Mel Shape: torch.Size([1, 128, 281])
Generated Mel Shape: torch.Size([1, 128, 150]), Reference Mel Shape: torch.Size([1, 128, 150])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 150])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 150])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 75])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 150])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 150])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 75])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 224/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5454/00025.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5454/00025.wav
Generated Mel Shape: torch.Size([1, 128, 177]), Reference Mel Shape: torch.Size([1, 128, 281])
Generated Mel Shape: torch.Size([1, 128, 177]), Reference Mel Shape: torch.Size([1, 128, 177])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 177])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 177])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 177])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 177])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 225/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5472/00007.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5472/00007.wav
Generated Mel Shape: torch.Size([1, 128, 209]), Reference Mel Shape: torch.Size([1, 128, 236])
Generated Mel Shape: torch.Size([1, 128, 209]), Reference Mel Shape: torch.Size([1, 128, 209])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 209])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 209])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 105])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 209])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 209])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 105])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])

[Processing Pair 226/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5489/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5489/00011.wav
Generated Mel Shape: torch.Size([1, 128, 233]), Reference Mel Shape: torch.Size([1, 128, 230])
Generated Mel Shape: torch.Size([1, 128, 230]), Reference Mel Shape: torch.Size([1, 128, 230])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 230])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 230])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 115])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 230])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 230])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 115])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])

[Processing Pair 227/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5590/00005.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5590/00005.wav
Generated Mel Shape: torch.Size([1, 128, 209]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 209]), Reference Mel Shape: torch.Size([1, 128, 209])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 209])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 209])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 105])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 209])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 209])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 105])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])

[Processing Pair 228/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5592/00045.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5592/00045.wav
Generated Mel Shape: torch.Size([1, 128, 170]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 170]), Reference Mel Shape: torch.Size([1, 128, 170])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 170])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 170])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 85])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 170])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 170])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 85])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 229/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5610/00004.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5610/00004.wav
Generated Mel Shape: torch.Size([1, 128, 228]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 204]), Reference Mel Shape: torch.Size([1, 128, 204])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 204])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 204])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 204])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 204])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])

[Processing Pair 230/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk58/00009.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk58/00009.wav
Generated Mel Shape: torch.Size([1, 128, 85]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 85]), Reference Mel Shape: torch.Size([1, 128, 85])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 85])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 85])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 11])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1408])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 85])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 85])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 11])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1408])

[Processing Pair 231/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5808/00014.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5808/00014.wav
Generated Mel Shape: torch.Size([1, 128, 187]), Reference Mel Shape: torch.Size([1, 128, 332])
Generated Mel Shape: torch.Size([1, 128, 187]), Reference Mel Shape: torch.Size([1, 128, 187])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 187])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 187])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 94])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 187])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 187])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 94])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 232/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5859/00008.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5859/00008.wav
Generated Mel Shape: torch.Size([1, 128, 151]), Reference Mel Shape: torch.Size([1, 128, 198])
Generated Mel Shape: torch.Size([1, 128, 151]), Reference Mel Shape: torch.Size([1, 128, 151])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 151])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 151])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 151])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 151])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 233/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5860/00012.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5860/00012.wav
Generated Mel Shape: torch.Size([1, 128, 155]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 234/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5868/00003.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5868/00003.wav
Generated Mel Shape: torch.Size([1, 128, 119]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 119]), Reference Mel Shape: torch.Size([1, 128, 119])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 119])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 119])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 119])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 119])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 235/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5908/00009.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5908/00009.wav
Generated Mel Shape: torch.Size([1, 128, 402]), Reference Mel Shape: torch.Size([1, 128, 480])
Generated Mel Shape: torch.Size([1, 128, 402]), Reference Mel Shape: torch.Size([1, 128, 402])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 402])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 402])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 201])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 51])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 51])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 6528])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 402])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 402])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 201])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 51])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 51])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 6528])

[Processing Pair 236/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5933/00018.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5933/00018.wav
Generated Mel Shape: torch.Size([1, 128, 214]), Reference Mel Shape: torch.Size([1, 128, 236])
Generated Mel Shape: torch.Size([1, 128, 214]), Reference Mel Shape: torch.Size([1, 128, 214])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 214])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 214])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 107])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 214])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 214])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 107])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])

[Processing Pair 237/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5933/00025.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5933/00025.wav
Generated Mel Shape: torch.Size([1, 128, 130]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 130]), Reference Mel Shape: torch.Size([1, 128, 130])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 130])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 130])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 130])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 130])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 238/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5933/00030.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5933/00030.wav
Generated Mel Shape: torch.Size([1, 128, 175]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 175]), Reference Mel Shape: torch.Size([1, 128, 175])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 175])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 175])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 88])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 175])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 175])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 88])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 239/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5933/00057.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5933/00057.wav
Generated Mel Shape: torch.Size([1, 128, 155]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 240/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5933/00060.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5933/00060.wav
Generated Mel Shape: torch.Size([1, 128, 424]), Reference Mel Shape: torch.Size([1, 128, 345])
Generated Mel Shape: torch.Size([1, 128, 345]), Reference Mel Shape: torch.Size([1, 128, 345])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 345])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 345])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 173])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 87])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 44])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 44])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5632])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 345])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 345])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 173])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 87])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 44])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 44])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5632])

[Processing Pair 241/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5934/00020.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5934/00020.wav
Generated Mel Shape: torch.Size([1, 128, 163]), Reference Mel Shape: torch.Size([1, 128, 230])
Generated Mel Shape: torch.Size([1, 128, 163]), Reference Mel Shape: torch.Size([1, 128, 163])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 163])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 163])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 163])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 163])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 242/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk5934/00042.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk5934/00042.wav
Generated Mel Shape: torch.Size([1, 128, 134]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 134]), Reference Mel Shape: torch.Size([1, 128, 134])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 243/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk6079/00007.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk6079/00007.wav
Generated Mel Shape: torch.Size([1, 128, 135]), Reference Mel Shape: torch.Size([1, 128, 134])
Generated Mel Shape: torch.Size([1, 128, 134]), Reference Mel Shape: torch.Size([1, 128, 134])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 244/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk6079/00008.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk6079/00008.wav
Generated Mel Shape: torch.Size([1, 128, 160]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 160]), Reference Mel Shape: torch.Size([1, 128, 160])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 245/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk6079/00012.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk6079/00012.wav
Generated Mel Shape: torch.Size([1, 128, 188]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 185]), Reference Mel Shape: torch.Size([1, 128, 185])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 185])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 185])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 93])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 185])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 185])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 93])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 246/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk6079/00013.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk6079/00013.wav
Generated Mel Shape: torch.Size([1, 128, 156]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 156]), Reference Mel Shape: torch.Size([1, 128, 156])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 156])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 156])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 78])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 156])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 156])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 78])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 247/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk6079/00027.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk6079/00027.wav
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 248/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk6282/00009.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk6282/00009.wav
Generated Mel Shape: torch.Size([1, 128, 178]), Reference Mel Shape: torch.Size([1, 128, 236])
Generated Mel Shape: torch.Size([1, 128, 178]), Reference Mel Shape: torch.Size([1, 128, 178])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 178])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 178])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 178])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 178])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 249/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk651/00004.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk651/00004.wav
Generated Mel Shape: torch.Size([1, 128, 141]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 141]), Reference Mel Shape: torch.Size([1, 128, 141])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 141])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 141])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 250/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk651/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk651/00006.wav
Generated Mel Shape: torch.Size([1, 128, 179]), Reference Mel Shape: torch.Size([1, 128, 198])
Generated Mel Shape: torch.Size([1, 128, 179]), Reference Mel Shape: torch.Size([1, 128, 179])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 179])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 179])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 179])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 179])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 251/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk6564/00003.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk6564/00003.wav
Generated Mel Shape: torch.Size([1, 128, 118]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 118]), Reference Mel Shape: torch.Size([1, 128, 118])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 118])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 118])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 118])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 118])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 252/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk6564/00005.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk6564/00005.wav
Generated Mel Shape: torch.Size([1, 128, 177]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 177]), Reference Mel Shape: torch.Size([1, 128, 177])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 177])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 177])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 177])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 177])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 253/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk6673/00018.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk6673/00018.wav
Generated Mel Shape: torch.Size([1, 128, 142]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 142]), Reference Mel Shape: torch.Size([1, 128, 142])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 142])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 142])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 142])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 142])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 254/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk6673/00025.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk6673/00025.wav
Generated Mel Shape: torch.Size([1, 128, 431]), Reference Mel Shape: torch.Size([1, 128, 460])
Generated Mel Shape: torch.Size([1, 128, 431]), Reference Mel Shape: torch.Size([1, 128, 431])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 431])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 431])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 216])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 108])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 54])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 54])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 6912])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 431])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 431])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 216])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 108])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 54])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 54])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 6912])

[Processing Pair 255/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk6675/00030.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk6675/00030.wav
Generated Mel Shape: torch.Size([1, 128, 157]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 157]), Reference Mel Shape: torch.Size([1, 128, 157])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 157])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 157])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 79])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 157])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 157])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 79])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 256/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk6762/00038.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk6762/00038.wav
Generated Mel Shape: torch.Size([1, 128, 163]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 163]), Reference Mel Shape: torch.Size([1, 128, 163])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 163])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 163])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 163])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 163])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 257/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk6762/00047.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk6762/00047.wav
Generated Mel Shape: torch.Size([1, 128, 159]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 159]), Reference Mel Shape: torch.Size([1, 128, 159])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 159])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 159])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 159])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 159])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 258/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk6923/00032.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk6923/00032.wav
Generated Mel Shape: torch.Size([1, 128, 98]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 98]), Reference Mel Shape: torch.Size([1, 128, 98])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 98])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 98])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 49])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 98])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 98])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 49])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])

[Processing Pair 259/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk6995/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk6995/00002.wav
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 260/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk6995/00016.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk6995/00016.wav
Generated Mel Shape: torch.Size([1, 128, 164]), Reference Mel Shape: torch.Size([1, 128, 198])
Generated Mel Shape: torch.Size([1, 128, 164]), Reference Mel Shape: torch.Size([1, 128, 164])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 164])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 164])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 164])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 164])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 261/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk6995/00017.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk6995/00017.wav
Generated Mel Shape: torch.Size([1, 128, 139]), Reference Mel Shape: torch.Size([1, 128, 243])
Generated Mel Shape: torch.Size([1, 128, 139]), Reference Mel Shape: torch.Size([1, 128, 139])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 139])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 139])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 139])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 139])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 262/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk6995/00046.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk6995/00046.wav
Generated Mel Shape: torch.Size([1, 128, 121]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 121]), Reference Mel Shape: torch.Size([1, 128, 121])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 121])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 121])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 121])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 121])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 263/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7001/00025.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7001/00025.wav
Generated Mel Shape: torch.Size([1, 128, 96]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 96]), Reference Mel Shape: torch.Size([1, 128, 96])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 96])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 96])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])

[Processing Pair 264/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7151/00001.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7151/00001.wav
Generated Mel Shape: torch.Size([1, 128, 132]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 132]), Reference Mel Shape: torch.Size([1, 128, 132])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 132])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 132])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 132])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 132])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 265/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7151/00008.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7151/00008.wav
Generated Mel Shape: torch.Size([1, 128, 142]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 142]), Reference Mel Shape: torch.Size([1, 128, 142])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 142])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 142])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 142])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 142])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 266/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7151/00013.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7151/00013.wav
Generated Mel Shape: torch.Size([1, 128, 229]), Reference Mel Shape: torch.Size([1, 128, 300])
Generated Mel Shape: torch.Size([1, 128, 229]), Reference Mel Shape: torch.Size([1, 128, 229])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 229])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 229])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 115])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 229])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 229])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 115])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])

[Processing Pair 267/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7151/00019.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7151/00019.wav
Generated Mel Shape: torch.Size([1, 128, 180]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 268/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7192/00028.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7192/00028.wav
Generated Mel Shape: torch.Size([1, 128, 141]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 141]), Reference Mel Shape: torch.Size([1, 128, 141])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 141])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 141])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 269/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7192/00029.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7192/00029.wav
Generated Mel Shape: torch.Size([1, 128, 111]), Reference Mel Shape: torch.Size([1, 128, 134])
Generated Mel Shape: torch.Size([1, 128, 111]), Reference Mel Shape: torch.Size([1, 128, 111])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 111])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 111])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 111])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 111])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 270/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7206/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7206/00011.wav
Generated Mel Shape: torch.Size([1, 128, 99]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 99]), Reference Mel Shape: torch.Size([1, 128, 99])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 99])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 99])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 99])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 99])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])

[Processing Pair 271/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7211/00004.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7211/00004.wav
Generated Mel Shape: torch.Size([1, 128, 125]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 125]), Reference Mel Shape: torch.Size([1, 128, 125])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 125])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 125])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 63])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 125])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 125])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 63])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 272/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7253/00013.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7253/00013.wav
Generated Mel Shape: torch.Size([1, 128, 271]), Reference Mel Shape: torch.Size([1, 128, 307])
Generated Mel Shape: torch.Size([1, 128, 271]), Reference Mel Shape: torch.Size([1, 128, 271])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 271])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 271])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 136])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 68])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 34])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 34])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4352])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 271])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 271])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 136])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 68])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 34])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 34])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4352])

[Processing Pair 273/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7253/00014.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7253/00014.wav
Generated Mel Shape: torch.Size([1, 128, 223]), Reference Mel Shape: torch.Size([1, 128, 236])
Generated Mel Shape: torch.Size([1, 128, 223]), Reference Mel Shape: torch.Size([1, 128, 223])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 223])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 223])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 223])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 223])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])

[Processing Pair 274/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7253/00015.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7253/00015.wav
Generated Mel Shape: torch.Size([1, 128, 258]), Reference Mel Shape: torch.Size([1, 128, 300])
Generated Mel Shape: torch.Size([1, 128, 258]), Reference Mel Shape: torch.Size([1, 128, 258])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 258])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 258])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 129])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 33])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4224])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 258])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 258])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 129])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 33])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4224])

[Processing Pair 275/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7256/00007.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7256/00007.wav
Generated Mel Shape: torch.Size([1, 128, 138]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 138]), Reference Mel Shape: torch.Size([1, 128, 138])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 138])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 138])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 69])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 138])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 138])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 69])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 276/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7256/00056.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7256/00056.wav
Generated Mel Shape: torch.Size([1, 128, 143]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 277/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7277/00013.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7277/00013.wav
Generated Mel Shape: torch.Size([1, 128, 163]), Reference Mel Shape: torch.Size([1, 128, 198])
Generated Mel Shape: torch.Size([1, 128, 163]), Reference Mel Shape: torch.Size([1, 128, 163])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 163])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 163])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 163])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 163])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 278/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7277/00030.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7277/00030.wav
Generated Mel Shape: torch.Size([1, 128, 185]), Reference Mel Shape: torch.Size([1, 128, 211])
Generated Mel Shape: torch.Size([1, 128, 185]), Reference Mel Shape: torch.Size([1, 128, 185])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 185])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 185])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 93])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 185])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 185])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 93])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 279/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7277/00052.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7277/00052.wav
Generated Mel Shape: torch.Size([1, 128, 116]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 116]), Reference Mel Shape: torch.Size([1, 128, 116])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 116])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 116])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 280/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7277/00060.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7277/00060.wav
Generated Mel Shape: torch.Size([1, 128, 206]), Reference Mel Shape: torch.Size([1, 128, 281])
Generated Mel Shape: torch.Size([1, 128, 206]), Reference Mel Shape: torch.Size([1, 128, 206])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 206])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 206])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 103])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 206])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 206])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 103])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])

[Processing Pair 281/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7283/00015.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7283/00015.wav
Generated Mel Shape: torch.Size([1, 128, 158]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 158]), Reference Mel Shape: torch.Size([1, 128, 158])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 158])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 158])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 79])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 158])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 158])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 79])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 282/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7283/00016.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7283/00016.wav
Generated Mel Shape: torch.Size([1, 128, 167]), Reference Mel Shape: torch.Size([1, 128, 198])
Generated Mel Shape: torch.Size([1, 128, 167]), Reference Mel Shape: torch.Size([1, 128, 167])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 167])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 167])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 84])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 167])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 167])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 84])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 283/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7289/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7289/00011.wav
Generated Mel Shape: torch.Size([1, 128, 232]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 224]), Reference Mel Shape: torch.Size([1, 128, 224])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 224])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 224])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 224])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 224])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])

[Processing Pair 284/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7289/00019.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7289/00019.wav
Generated Mel Shape: torch.Size([1, 128, 128]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 128]), Reference Mel Shape: torch.Size([1, 128, 128])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 128])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 128])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 285/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7343/00001.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7343/00001.wav
Generated Mel Shape: torch.Size([1, 128, 87]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 87]), Reference Mel Shape: torch.Size([1, 128, 87])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 87])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 87])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 11])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1408])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 87])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 87])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 11])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1408])

[Processing Pair 286/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7343/00052.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7343/00052.wav
Generated Mel Shape: torch.Size([1, 128, 125]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 125]), Reference Mel Shape: torch.Size([1, 128, 125])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 125])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 125])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 63])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 125])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 125])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 63])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 287/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7377/00016.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7377/00016.wav
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 161])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 161])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 161])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 161])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 161])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 288/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7377/00020.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7377/00020.wav
Generated Mel Shape: torch.Size([1, 128, 135]), Reference Mel Shape: torch.Size([1, 128, 134])
Generated Mel Shape: torch.Size([1, 128, 134]), Reference Mel Shape: torch.Size([1, 128, 134])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 289/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7378/00001.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7378/00001.wav
Generated Mel Shape: torch.Size([1, 128, 167]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 147]), Reference Mel Shape: torch.Size([1, 128, 147])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 147])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 147])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 290/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7378/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7378/00002.wav
Generated Mel Shape: torch.Size([1, 128, 245]), Reference Mel Shape: torch.Size([1, 128, 275])
Generated Mel Shape: torch.Size([1, 128, 245]), Reference Mel Shape: torch.Size([1, 128, 245])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 245])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 245])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 123])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 62])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 31])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 31])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3968])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 245])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 245])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 123])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 62])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 31])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 31])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3968])

[Processing Pair 291/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7413/00005.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7413/00005.wav
Generated Mel Shape: torch.Size([1, 128, 231]), Reference Mel Shape: torch.Size([1, 128, 268])
Generated Mel Shape: torch.Size([1, 128, 231]), Reference Mel Shape: torch.Size([1, 128, 231])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 231])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 231])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 231])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 231])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])

[Processing Pair 292/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7413/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7413/00006.wav
Generated Mel Shape: torch.Size([1, 128, 134]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 134]), Reference Mel Shape: torch.Size([1, 128, 134])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 293/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7442/00005.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7442/00005.wav
Generated Mel Shape: torch.Size([1, 128, 442]), Reference Mel Shape: torch.Size([1, 128, 460])
Generated Mel Shape: torch.Size([1, 128, 442]), Reference Mel Shape: torch.Size([1, 128, 442])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 442])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 442])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 221])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 111])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 56])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 56])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 7168])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 442])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 442])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 221])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 111])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 56])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 56])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 7168])

[Processing Pair 294/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7442/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7442/00011.wav
Generated Mel Shape: torch.Size([1, 128, 207]), Reference Mel Shape: torch.Size([1, 128, 236])
Generated Mel Shape: torch.Size([1, 128, 207]), Reference Mel Shape: torch.Size([1, 128, 207])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 207])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 207])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 104])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 207])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 207])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 104])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])

[Processing Pair 295/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7442/00030.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7442/00030.wav
Generated Mel Shape: torch.Size([1, 128, 210]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 204]), Reference Mel Shape: torch.Size([1, 128, 204])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 204])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 204])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 204])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 204])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])

[Processing Pair 296/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7469/00016.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7469/00016.wav
Generated Mel Shape: torch.Size([1, 128, 112]), Reference Mel Shape: torch.Size([1, 128, 134])
Generated Mel Shape: torch.Size([1, 128, 112]), Reference Mel Shape: torch.Size([1, 128, 112])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 112])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 112])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 297/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7472/00015.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7472/00015.wav
Generated Mel Shape: torch.Size([1, 128, 495]), Reference Mel Shape: torch.Size([1, 128, 409])
Generated Mel Shape: torch.Size([1, 128, 409]), Reference Mel Shape: torch.Size([1, 128, 409])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 409])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 409])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 205])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 103])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 52])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 52])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 6656])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 409])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 409])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 205])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 103])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 52])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 52])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 6656])

[Processing Pair 298/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7523/00086.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7523/00086.wav
Generated Mel Shape: torch.Size([1, 128, 112]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 112]), Reference Mel Shape: torch.Size([1, 128, 112])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 112])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 112])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 299/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7523/00103.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7523/00103.wav
Generated Mel Shape: torch.Size([1, 128, 144]), Reference Mel Shape: torch.Size([1, 128, 198])
Generated Mel Shape: torch.Size([1, 128, 144]), Reference Mel Shape: torch.Size([1, 128, 144])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 144])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 144])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 144])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 144])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 300/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7528/00017.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7528/00017.wav
Generated Mel Shape: torch.Size([1, 128, 141]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 301/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7530/00015.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7530/00015.wav
Generated Mel Shape: torch.Size([1, 128, 210]), Reference Mel Shape: torch.Size([1, 128, 230])
Generated Mel Shape: torch.Size([1, 128, 210]), Reference Mel Shape: torch.Size([1, 128, 210])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 210])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 210])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 105])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 210])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 210])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 105])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])

[Processing Pair 302/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7533/00022.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7533/00022.wav
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 131])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 303/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7537/00007.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7537/00007.wav
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 304/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7537/00010.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7537/00010.wav
Generated Mel Shape: torch.Size([1, 128, 143]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 143]), Reference Mel Shape: torch.Size([1, 128, 143])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 143])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 143])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 143])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 143])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 305/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7543/00008.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7543/00008.wav
Generated Mel Shape: torch.Size([1, 128, 143]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 143]), Reference Mel Shape: torch.Size([1, 128, 143])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 143])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 143])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 143])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 143])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 306/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7543/00127.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7543/00127.wav
Generated Mel Shape: torch.Size([1, 128, 148]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 147]), Reference Mel Shape: torch.Size([1, 128, 147])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 147])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 147])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 307/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7554/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7554/00002.wav
Generated Mel Shape: torch.Size([1, 128, 142]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 142]), Reference Mel Shape: torch.Size([1, 128, 142])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 142])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 142])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 142])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 142])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 308/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7582/00013.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7582/00013.wav
Generated Mel Shape: torch.Size([1, 128, 183]), Reference Mel Shape: torch.Size([1, 128, 217])
Generated Mel Shape: torch.Size([1, 128, 183]), Reference Mel Shape: torch.Size([1, 128, 183])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 183])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 183])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 92])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 183])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 183])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 92])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 309/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7582/00014.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7582/00014.wav
Generated Mel Shape: torch.Size([1, 128, 176]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 176]), Reference Mel Shape: torch.Size([1, 128, 176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 176])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 176])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 88])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 176])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 176])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 88])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 310/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7582/00016.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7582/00016.wav
Generated Mel Shape: torch.Size([1, 128, 121]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 121]), Reference Mel Shape: torch.Size([1, 128, 121])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 121])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 121])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 121])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 121])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 311/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7582/00020.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7582/00020.wav
Generated Mel Shape: torch.Size([1, 128, 119]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 119]), Reference Mel Shape: torch.Size([1, 128, 119])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 119])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 119])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 119])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 119])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 312/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7596/00007.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7596/00007.wav
Generated Mel Shape: torch.Size([1, 128, 116]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 116]), Reference Mel Shape: torch.Size([1, 128, 116])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 116])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 116])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 313/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7596/00013.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7596/00013.wav
Generated Mel Shape: torch.Size([1, 128, 102]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 102]), Reference Mel Shape: torch.Size([1, 128, 102])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 102])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 102])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])

[Processing Pair 314/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7596/00085.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7596/00085.wav
Generated Mel Shape: torch.Size([1, 128, 98]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 98]), Reference Mel Shape: torch.Size([1, 128, 98])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 98])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 98])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 49])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 98])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 98])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 49])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])

[Processing Pair 315/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7596/00098.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7596/00098.wav
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 316/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7596/00139.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7596/00139.wav
Generated Mel Shape: torch.Size([1, 128, 112]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 112]), Reference Mel Shape: torch.Size([1, 128, 112])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 112])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 112])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 317/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7613/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7613/00002.wav
Generated Mel Shape: torch.Size([1, 128, 99]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 99]), Reference Mel Shape: torch.Size([1, 128, 99])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 99])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 99])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 99])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 99])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])

[Processing Pair 318/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7613/00003.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7613/00003.wav
Generated Mel Shape: torch.Size([1, 128, 152]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 152]), Reference Mel Shape: torch.Size([1, 128, 152])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 152])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 152])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 152])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 152])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 319/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7613/00005.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7613/00005.wav
Generated Mel Shape: torch.Size([1, 128, 142]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 142]), Reference Mel Shape: torch.Size([1, 128, 142])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 142])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 142])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 142])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 142])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 320/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7676/00013.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7676/00013.wav
Generated Mel Shape: torch.Size([1, 128, 186]), Reference Mel Shape: torch.Size([1, 128, 294])
Generated Mel Shape: torch.Size([1, 128, 186]), Reference Mel Shape: torch.Size([1, 128, 186])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 186])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 186])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 93])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 186])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 186])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 93])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 321/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7676/00020.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7676/00020.wav
Generated Mel Shape: torch.Size([1, 128, 101]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 101]), Reference Mel Shape: torch.Size([1, 128, 101])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 101])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 101])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])

[Processing Pair 322/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7728/00024.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7728/00024.wav
Generated Mel Shape: torch.Size([1, 128, 195]), Reference Mel Shape: torch.Size([1, 128, 230])
Generated Mel Shape: torch.Size([1, 128, 195]), Reference Mel Shape: torch.Size([1, 128, 195])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 195])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 195])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 98])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 49])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 195])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 195])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 98])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 49])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])

[Processing Pair 323/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7728/00029.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7728/00029.wav
Generated Mel Shape: torch.Size([1, 128, 146]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 146]), Reference Mel Shape: torch.Size([1, 128, 146])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 146])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 146])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 146])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 146])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 324/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7728/00030.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7728/00030.wav
Generated Mel Shape: torch.Size([1, 128, 186]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 172]), Reference Mel Shape: torch.Size([1, 128, 172])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 325/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7728/00035.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7728/00035.wav
Generated Mel Shape: torch.Size([1, 128, 310]), Reference Mel Shape: torch.Size([1, 128, 300])
Generated Mel Shape: torch.Size([1, 128, 300]), Reference Mel Shape: torch.Size([1, 128, 300])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 300])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 300])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 150])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 75])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 38])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4864])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 300])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 300])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 150])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 75])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 38])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4864])

[Processing Pair 326/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7744/00027.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7744/00027.wav
Generated Mel Shape: torch.Size([1, 128, 121]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 121]), Reference Mel Shape: torch.Size([1, 128, 121])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 121])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 121])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 121])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 121])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 327/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7745/00010.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7745/00010.wav
Generated Mel Shape: torch.Size([1, 128, 144]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 144]), Reference Mel Shape: torch.Size([1, 128, 144])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 144])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 144])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 144])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 144])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 328/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7790/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7790/00002.wav
Generated Mel Shape: torch.Size([1, 128, 158]), Reference Mel Shape: torch.Size([1, 128, 217])
Generated Mel Shape: torch.Size([1, 128, 158]), Reference Mel Shape: torch.Size([1, 128, 158])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 158])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 158])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 79])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 158])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 158])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 79])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 329/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7859/00141.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7859/00141.wav
Generated Mel Shape: torch.Size([1, 128, 258]), Reference Mel Shape: torch.Size([1, 128, 307])
Generated Mel Shape: torch.Size([1, 128, 258]), Reference Mel Shape: torch.Size([1, 128, 258])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 258])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 258])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 129])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 33])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4224])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 258])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 258])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 129])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 33])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4224])

[Processing Pair 330/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7886/00009.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7886/00009.wav
Generated Mel Shape: torch.Size([1, 128, 160]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 160]), Reference Mel Shape: torch.Size([1, 128, 160])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 331/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk7987/00010.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk7987/00010.wav
Generated Mel Shape: torch.Size([1, 128, 201]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 201]), Reference Mel Shape: torch.Size([1, 128, 201])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 201])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 201])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 201])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 201])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])

[Processing Pair 332/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8007/00015.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8007/00015.wav
Generated Mel Shape: torch.Size([1, 128, 356]), Reference Mel Shape: torch.Size([1, 128, 339])
Generated Mel Shape: torch.Size([1, 128, 339]), Reference Mel Shape: torch.Size([1, 128, 339])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 339])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 339])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 170])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 85])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 43])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 43])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5504])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 339])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 339])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 170])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 85])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 43])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 43])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5504])

[Processing Pair 333/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8021/00013.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8021/00013.wav
Generated Mel Shape: torch.Size([1, 128, 114]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 114]), Reference Mel Shape: torch.Size([1, 128, 114])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 114])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 114])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 114])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 114])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 334/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8021/00014.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8021/00014.wav
Generated Mel Shape: torch.Size([1, 128, 100]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 100]), Reference Mel Shape: torch.Size([1, 128, 100])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 100])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 100])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 100])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 100])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])

[Processing Pair 335/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8021/00015.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8021/00015.wav
Generated Mel Shape: torch.Size([1, 128, 238]), Reference Mel Shape: torch.Size([1, 128, 281])
Generated Mel Shape: torch.Size([1, 128, 238]), Reference Mel Shape: torch.Size([1, 128, 238])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 238])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 238])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 119])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 30])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3840])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 238])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 238])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 119])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 30])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3840])

[Processing Pair 336/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8032/00029.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8032/00029.wav
Generated Mel Shape: torch.Size([1, 128, 171]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 171]), Reference Mel Shape: torch.Size([1, 128, 171])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 171])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 171])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 171])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 171])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 337/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8047/00009.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8047/00009.wav
Generated Mel Shape: torch.Size([1, 128, 302]), Reference Mel Shape: torch.Size([1, 128, 345])
Generated Mel Shape: torch.Size([1, 128, 302]), Reference Mel Shape: torch.Size([1, 128, 302])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 302])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 302])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 151])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 38])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4864])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 302])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 302])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 151])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 38])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4864])

[Processing Pair 338/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8047/00020.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8047/00020.wav
Generated Mel Shape: torch.Size([1, 128, 114]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 114]), Reference Mel Shape: torch.Size([1, 128, 114])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 114])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 114])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 114])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 114])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 339/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8047/00024.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8047/00024.wav
Generated Mel Shape: torch.Size([1, 128, 108]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 108]), Reference Mel Shape: torch.Size([1, 128, 108])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 108])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 108])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 108])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 108])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 340/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8047/00033.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8047/00033.wav
Generated Mel Shape: torch.Size([1, 128, 139]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 139]), Reference Mel Shape: torch.Size([1, 128, 139])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 139])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 139])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 139])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 139])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 341/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8047/00036.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8047/00036.wav
Generated Mel Shape: torch.Size([1, 128, 213]), Reference Mel Shape: torch.Size([1, 128, 236])
Generated Mel Shape: torch.Size([1, 128, 213]), Reference Mel Shape: torch.Size([1, 128, 213])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 213])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 213])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 107])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 213])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 213])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 107])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])

[Processing Pair 342/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8082/00054.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8082/00054.wav
Generated Mel Shape: torch.Size([1, 128, 107]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 107]), Reference Mel Shape: torch.Size([1, 128, 107])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 107])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 107])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 107])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 107])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 343/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8206/00012.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8206/00012.wav
Generated Mel Shape: torch.Size([1, 128, 193]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 193]), Reference Mel Shape: torch.Size([1, 128, 193])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 193])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 193])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 97])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 49])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 193])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 193])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 97])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 49])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])

[Processing Pair 344/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8225/00046.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8225/00046.wav
Generated Mel Shape: torch.Size([1, 128, 95]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 95]), Reference Mel Shape: torch.Size([1, 128, 95])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 95])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 95])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 95])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 95])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])

[Processing Pair 345/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8225/00051.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8225/00051.wav
Generated Mel Shape: torch.Size([1, 128, 175]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 172]), Reference Mel Shape: torch.Size([1, 128, 172])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 346/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8258/00015.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8258/00015.wav
Generated Mel Shape: torch.Size([1, 128, 81]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 81]), Reference Mel Shape: torch.Size([1, 128, 81])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 81])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 11])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1408])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 81])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 11])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1408])

[Processing Pair 347/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8258/00021.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8258/00021.wav
Generated Mel Shape: torch.Size([1, 128, 146]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 348/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8258/00024.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8258/00024.wav
Generated Mel Shape: torch.Size([1, 128, 128]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 128]), Reference Mel Shape: torch.Size([1, 128, 128])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 128])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 128])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 349/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8258/00040.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8258/00040.wav
Generated Mel Shape: torch.Size([1, 128, 200]), Reference Mel Shape: torch.Size([1, 128, 217])
Generated Mel Shape: torch.Size([1, 128, 200]), Reference Mel Shape: torch.Size([1, 128, 200])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 200])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 200])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 100])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 200])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 200])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 100])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])

[Processing Pair 350/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk829/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk829/00002.wav
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 131])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 351/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk830/00045.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk830/00045.wav
Generated Mel Shape: torch.Size([1, 128, 102]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 102]), Reference Mel Shape: torch.Size([1, 128, 102])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 102])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 102])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])

[Processing Pair 352/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8322/00007.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8322/00007.wav
Generated Mel Shape: torch.Size([1, 128, 139]), Reference Mel Shape: torch.Size([1, 128, 134])
Generated Mel Shape: torch.Size([1, 128, 134]), Reference Mel Shape: torch.Size([1, 128, 134])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 353/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8364/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8364/00006.wav
Generated Mel Shape: torch.Size([1, 128, 150]), Reference Mel Shape: torch.Size([1, 128, 256])
Generated Mel Shape: torch.Size([1, 128, 150]), Reference Mel Shape: torch.Size([1, 128, 150])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 150])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 150])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 75])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 150])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 150])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 75])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 354/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8365/00003.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8365/00003.wav
Generated Mel Shape: torch.Size([1, 128, 191]), Reference Mel Shape: torch.Size([1, 128, 249])
Generated Mel Shape: torch.Size([1, 128, 191]), Reference Mel Shape: torch.Size([1, 128, 191])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 191])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 191])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 191])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 191])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 355/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk846/00025.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk846/00025.wav
Generated Mel Shape: torch.Size([1, 128, 197]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 192]), Reference Mel Shape: torch.Size([1, 128, 192])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 192])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 192])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 192])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 192])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 356/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8461/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8461/00011.wav
Generated Mel Shape: torch.Size([1, 128, 101]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 101]), Reference Mel Shape: torch.Size([1, 128, 101])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 101])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 101])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])

[Processing Pair 357/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8479/00021.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8479/00021.wav
Generated Mel Shape: torch.Size([1, 128, 163]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 163]), Reference Mel Shape: torch.Size([1, 128, 163])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 163])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 163])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 163])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 163])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 358/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8479/00033.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8479/00033.wav
Generated Mel Shape: torch.Size([1, 128, 169]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 169]), Reference Mel Shape: torch.Size([1, 128, 169])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 169])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 169])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 85])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 169])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 169])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 85])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 359/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk848/00021.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk848/00021.wav
Generated Mel Shape: torch.Size([1, 128, 104]), Reference Mel Shape: torch.Size([1, 128, 134])
Generated Mel Shape: torch.Size([1, 128, 104]), Reference Mel Shape: torch.Size([1, 128, 104])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 104])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 104])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 104])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 104])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])

[Processing Pair 360/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk848/00022.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk848/00022.wav
Generated Mel Shape: torch.Size([1, 128, 110]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 110]), Reference Mel Shape: torch.Size([1, 128, 110])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 110])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 110])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 55])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 110])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 110])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 55])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 361/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk848/00056.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk848/00056.wav
Generated Mel Shape: torch.Size([1, 128, 154]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 147]), Reference Mel Shape: torch.Size([1, 128, 147])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 147])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 147])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 362/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk85/00014.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk85/00014.wav
Generated Mel Shape: torch.Size([1, 128, 179]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 179]), Reference Mel Shape: torch.Size([1, 128, 179])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 179])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 179])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 179])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 179])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 363/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8502/00015.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8502/00015.wav
Generated Mel Shape: torch.Size([1, 128, 154]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 364/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8516/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8516/00006.wav
Generated Mel Shape: torch.Size([1, 128, 156]), Reference Mel Shape: torch.Size([1, 128, 236])
Generated Mel Shape: torch.Size([1, 128, 156]), Reference Mel Shape: torch.Size([1, 128, 156])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 156])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 156])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 78])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 156])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 156])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 78])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 365/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8599/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8599/00006.wav
Generated Mel Shape: torch.Size([1, 128, 80]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 80]), Reference Mel Shape: torch.Size([1, 128, 80])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 80])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 10])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 10])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 10])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1280])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 80])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 10])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 10])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 10])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1280])

[Processing Pair 366/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8599/00021.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8599/00021.wav
Generated Mel Shape: torch.Size([1, 128, 306]), Reference Mel Shape: torch.Size([1, 128, 339])
Generated Mel Shape: torch.Size([1, 128, 306]), Reference Mel Shape: torch.Size([1, 128, 306])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 306])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 306])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 39])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 39])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4992])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 306])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 306])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 39])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 39])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4992])

[Processing Pair 367/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8599/00030.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8599/00030.wav
Generated Mel Shape: torch.Size([1, 128, 179]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 179]), Reference Mel Shape: torch.Size([1, 128, 179])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 179])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 179])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 179])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 179])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 368/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8599/00092.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8599/00092.wav
Generated Mel Shape: torch.Size([1, 128, 314]), Reference Mel Shape: torch.Size([1, 128, 384])
Generated Mel Shape: torch.Size([1, 128, 314]), Reference Mel Shape: torch.Size([1, 128, 314])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 314])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 314])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 157])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 79])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 40])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 40])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5120])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 314])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 314])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 157])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 79])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 40])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 40])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5120])

[Processing Pair 369/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8599/00094.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8599/00094.wav
Generated Mel Shape: torch.Size([1, 128, 146]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 146]), Reference Mel Shape: torch.Size([1, 128, 146])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 146])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 146])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 146])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 146])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 370/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8599/00095.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8599/00095.wav
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 371/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00001.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00001.wav
Generated Mel Shape: torch.Size([1, 128, 92]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 92]), Reference Mel Shape: torch.Size([1, 128, 92])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 92])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 92])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 92])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 92])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])

[Processing Pair 372/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00002.wav
Generated Mel Shape: torch.Size([1, 128, 177]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 160]), Reference Mel Shape: torch.Size([1, 128, 160])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 373/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00003.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00003.wav
Generated Mel Shape: torch.Size([1, 128, 108]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 108]), Reference Mel Shape: torch.Size([1, 128, 108])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 108])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 108])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 108])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 108])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 374/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00004.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00004.wav
Generated Mel Shape: torch.Size([1, 128, 139]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 139]), Reference Mel Shape: torch.Size([1, 128, 139])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 139])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 139])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 139])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 139])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 375/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00006.wav
Generated Mel Shape: torch.Size([1, 128, 151]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 376/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00007.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00007.wav
Generated Mel Shape: torch.Size([1, 128, 180]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 180]), Reference Mel Shape: torch.Size([1, 128, 180])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 180])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 180])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 180])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 180])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 377/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00010.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00010.wav
Generated Mel Shape: torch.Size([1, 128, 215]), Reference Mel Shape: torch.Size([1, 128, 243])
Generated Mel Shape: torch.Size([1, 128, 215]), Reference Mel Shape: torch.Size([1, 128, 215])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 215])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 215])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 108])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 215])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 215])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 108])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])

[Processing Pair 378/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00011.wav
Generated Mel Shape: torch.Size([1, 128, 91]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 91]), Reference Mel Shape: torch.Size([1, 128, 91])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 91])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 91])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 91])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 91])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])

[Processing Pair 379/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00012.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00012.wav
Generated Mel Shape: torch.Size([1, 128, 155]), Reference Mel Shape: torch.Size([1, 128, 211])
Generated Mel Shape: torch.Size([1, 128, 155]), Reference Mel Shape: torch.Size([1, 128, 155])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 155])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 155])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 78])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 155])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 155])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 78])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 380/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00013.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00013.wav
Generated Mel Shape: torch.Size([1, 128, 148]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 148]), Reference Mel Shape: torch.Size([1, 128, 148])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 148])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 148])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 148])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 148])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 381/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00016.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00016.wav
Generated Mel Shape: torch.Size([1, 128, 382]), Reference Mel Shape: torch.Size([1, 128, 384])
Generated Mel Shape: torch.Size([1, 128, 382]), Reference Mel Shape: torch.Size([1, 128, 382])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 382])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 382])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 191])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 48])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 48])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 6144])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 382])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 382])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 191])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 48])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 48])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 6144])

[Processing Pair 382/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00017.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00017.wav
Generated Mel Shape: torch.Size([1, 128, 250]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 192]), Reference Mel Shape: torch.Size([1, 128, 192])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 192])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 192])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 192])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 192])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 383/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00019.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00019.wav
Generated Mel Shape: torch.Size([1, 128, 113]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 113]), Reference Mel Shape: torch.Size([1, 128, 113])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 113])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 113])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 113])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 113])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 384/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00020.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00020.wav
Generated Mel Shape: torch.Size([1, 128, 200]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 200]), Reference Mel Shape: torch.Size([1, 128, 200])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 200])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 200])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 100])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 200])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 200])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 100])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])

[Processing Pair 385/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00021.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00021.wav
Generated Mel Shape: torch.Size([1, 128, 177]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 177]), Reference Mel Shape: torch.Size([1, 128, 177])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 177])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 177])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 177])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 177])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 386/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00026.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00026.wav
Generated Mel Shape: torch.Size([1, 128, 128]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 128]), Reference Mel Shape: torch.Size([1, 128, 128])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 128])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 128])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 387/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00027.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00027.wav
Generated Mel Shape: torch.Size([1, 128, 123]), Reference Mel Shape: torch.Size([1, 128, 134])
Generated Mel Shape: torch.Size([1, 128, 123]), Reference Mel Shape: torch.Size([1, 128, 123])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 123])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 123])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 62])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 123])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 123])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 62])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 388/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00031.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00031.wav
Generated Mel Shape: torch.Size([1, 128, 251]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 185]), Reference Mel Shape: torch.Size([1, 128, 185])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 185])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 185])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 93])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 185])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 185])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 93])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 389/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00032.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00032.wav
Generated Mel Shape: torch.Size([1, 128, 239]), Reference Mel Shape: torch.Size([1, 128, 288])
Generated Mel Shape: torch.Size([1, 128, 239]), Reference Mel Shape: torch.Size([1, 128, 239])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 239])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 239])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 120])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 30])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3840])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 239])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 239])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 120])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 30])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3840])

[Processing Pair 390/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00039.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00039.wav
Generated Mel Shape: torch.Size([1, 128, 155]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 391/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00044.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00044.wav
Generated Mel Shape: torch.Size([1, 128, 160]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 160]), Reference Mel Shape: torch.Size([1, 128, 160])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 392/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00045.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00045.wav
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 161])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 161])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 161])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 161])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 161])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 393/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk876/00054.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk876/00054.wav
Generated Mel Shape: torch.Size([1, 128, 152]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 152]), Reference Mel Shape: torch.Size([1, 128, 152])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 152])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 152])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 152])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 152])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 394/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk882/00017.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk882/00017.wav
Generated Mel Shape: torch.Size([1, 128, 145]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 145]), Reference Mel Shape: torch.Size([1, 128, 145])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 145])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 145])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 145])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 145])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 395/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk882/00025.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk882/00025.wav
Generated Mel Shape: torch.Size([1, 128, 154]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 147]), Reference Mel Shape: torch.Size([1, 128, 147])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 147])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 147])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 396/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk884/00014.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk884/00014.wav
Generated Mel Shape: torch.Size([1, 128, 184]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 160]), Reference Mel Shape: torch.Size([1, 128, 160])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 397/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk886/00001.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk886/00001.wav
Generated Mel Shape: torch.Size([1, 128, 212]), Reference Mel Shape: torch.Size([1, 128, 256])
Generated Mel Shape: torch.Size([1, 128, 212]), Reference Mel Shape: torch.Size([1, 128, 212])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 212])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 212])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 106])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 212])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 212])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 106])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])

[Processing Pair 398/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk886/00005.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk886/00005.wav
Generated Mel Shape: torch.Size([1, 128, 254]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 224]), Reference Mel Shape: torch.Size([1, 128, 224])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 224])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 224])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 224])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 224])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])

[Processing Pair 399/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk886/00008.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk886/00008.wav
Generated Mel Shape: torch.Size([1, 128, 280]), Reference Mel Shape: torch.Size([1, 128, 339])
Generated Mel Shape: torch.Size([1, 128, 280]), Reference Mel Shape: torch.Size([1, 128, 280])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 280])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 280])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 35])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4480])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 280])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 280])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 35])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4480])

[Processing Pair 400/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk886/00010.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk886/00010.wav
Generated Mel Shape: torch.Size([1, 128, 171]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 171]), Reference Mel Shape: torch.Size([1, 128, 171])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 171])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 171])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 171])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 171])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 401/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk886/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk886/00011.wav
Generated Mel Shape: torch.Size([1, 128, 120]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 120]), Reference Mel Shape: torch.Size([1, 128, 120])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 120])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 120])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 120])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 120])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 402/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk886/00013.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk886/00013.wav
Generated Mel Shape: torch.Size([1, 128, 186]), Reference Mel Shape: torch.Size([1, 128, 236])
Generated Mel Shape: torch.Size([1, 128, 186]), Reference Mel Shape: torch.Size([1, 128, 186])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 186])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 186])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 93])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 186])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 186])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 93])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 403/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk886/00016.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk886/00016.wav
Generated Mel Shape: torch.Size([1, 128, 157]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 147]), Reference Mel Shape: torch.Size([1, 128, 147])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 147])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 147])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 404/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk886/00018.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk886/00018.wav
Generated Mel Shape: torch.Size([1, 128, 230]), Reference Mel Shape: torch.Size([1, 128, 288])
Generated Mel Shape: torch.Size([1, 128, 230]), Reference Mel Shape: torch.Size([1, 128, 230])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 230])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 230])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 115])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 230])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 230])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 115])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])

[Processing Pair 405/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk886/00019.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk886/00019.wav
Generated Mel Shape: torch.Size([1, 128, 170]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 170]), Reference Mel Shape: torch.Size([1, 128, 170])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 170])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 170])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 85])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 170])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 170])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 85])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 406/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk886/00023.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk886/00023.wav
Generated Mel Shape: torch.Size([1, 128, 152]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 152]), Reference Mel Shape: torch.Size([1, 128, 152])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 152])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 152])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 152])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 152])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 407/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk886/00026.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk886/00026.wav
Generated Mel Shape: torch.Size([1, 128, 160]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 408/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk886/00036.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk886/00036.wav
Generated Mel Shape: torch.Size([1, 128, 217]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 217]), Reference Mel Shape: torch.Size([1, 128, 217])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 217])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 217])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 109])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 55])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 217])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 217])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 109])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 55])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])

[Processing Pair 409/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8971/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8971/00011.wav
Generated Mel Shape: torch.Size([1, 128, 180]), Reference Mel Shape: torch.Size([1, 128, 249])
Generated Mel Shape: torch.Size([1, 128, 180]), Reference Mel Shape: torch.Size([1, 128, 180])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 180])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 180])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 180])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 180])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 410/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8972/00029.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8972/00029.wav
Generated Mel Shape: torch.Size([1, 128, 172]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 172]), Reference Mel Shape: torch.Size([1, 128, 172])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 411/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8973/00018.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8973/00018.wav
Generated Mel Shape: torch.Size([1, 128, 247]), Reference Mel Shape: torch.Size([1, 128, 211])
Generated Mel Shape: torch.Size([1, 128, 211]), Reference Mel Shape: torch.Size([1, 128, 211])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 211])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 211])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 106])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 211])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 211])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 106])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])

[Processing Pair 412/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8973/00026.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8973/00026.wav
Generated Mel Shape: torch.Size([1, 128, 242]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 224]), Reference Mel Shape: torch.Size([1, 128, 224])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 224])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 224])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 224])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 224])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])

[Processing Pair 413/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8974/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8974/00011.wav
Generated Mel Shape: torch.Size([1, 128, 180]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 180]), Reference Mel Shape: torch.Size([1, 128, 180])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 180])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 180])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 180])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 180])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 414/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8975/00008.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8975/00008.wav
Generated Mel Shape: torch.Size([1, 128, 184]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 184]), Reference Mel Shape: torch.Size([1, 128, 184])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 184])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 184])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 92])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 184])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 184])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 92])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 415/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8976/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8976/00002.wav
Generated Mel Shape: torch.Size([1, 128, 105]), Reference Mel Shape: torch.Size([1, 128, 134])
Generated Mel Shape: torch.Size([1, 128, 105]), Reference Mel Shape: torch.Size([1, 128, 105])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 105])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 105])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 105])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 105])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 416/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8977/00024.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8977/00024.wav
Generated Mel Shape: torch.Size([1, 128, 151]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 417/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8978/00057.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8978/00057.wav
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 134])
Generated Mel Shape: torch.Size([1, 128, 134]), Reference Mel Shape: torch.Size([1, 128, 134])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 418/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8979/00081.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8979/00081.wav
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 131])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 419/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8980/00068.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8980/00068.wav
Generated Mel Shape: torch.Size([1, 128, 129]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 129]), Reference Mel Shape: torch.Size([1, 128, 129])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 129])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 129])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 129])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 129])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 420/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8980/00082.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8980/00082.wav
Generated Mel Shape: torch.Size([1, 128, 107]), Reference Mel Shape: torch.Size([1, 128, 134])
Generated Mel Shape: torch.Size([1, 128, 107]), Reference Mel Shape: torch.Size([1, 128, 107])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 107])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 107])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 107])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 107])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 421/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8981/00012.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8981/00012.wav
Generated Mel Shape: torch.Size([1, 128, 226]), Reference Mel Shape: torch.Size([1, 128, 217])
Generated Mel Shape: torch.Size([1, 128, 217]), Reference Mel Shape: torch.Size([1, 128, 217])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 217])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 217])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 109])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 55])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 217])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 217])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 109])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 55])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])

[Processing Pair 422/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8982/00032.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8982/00032.wav
Generated Mel Shape: torch.Size([1, 128, 272]), Reference Mel Shape: torch.Size([1, 128, 294])
Generated Mel Shape: torch.Size([1, 128, 272]), Reference Mel Shape: torch.Size([1, 128, 272])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 272])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 272])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 136])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 68])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 34])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 34])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4352])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 272])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 272])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 136])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 68])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 34])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 34])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4352])

[Processing Pair 423/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8982/00035.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8982/00035.wav
Generated Mel Shape: torch.Size([1, 128, 143]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 143]), Reference Mel Shape: torch.Size([1, 128, 143])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 143])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 143])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 143])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 143])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 424/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8982/00036.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8982/00036.wav
Generated Mel Shape: torch.Size([1, 128, 293]), Reference Mel Shape: torch.Size([1, 128, 275])
Generated Mel Shape: torch.Size([1, 128, 275]), Reference Mel Shape: torch.Size([1, 128, 275])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 275])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 275])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 138])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 69])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 35])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4480])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 275])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 275])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 138])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 69])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 35])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4480])

[Processing Pair 425/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8983/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8983/00011.wav
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 300])
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 161])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 161])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 161])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 161])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 161])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 426/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8983/00014.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8983/00014.wav
Generated Mel Shape: torch.Size([1, 128, 144]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 144]), Reference Mel Shape: torch.Size([1, 128, 144])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 144])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 144])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 144])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 144])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 427/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8985/00076.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8985/00076.wav
Generated Mel Shape: torch.Size([1, 128, 165]), Reference Mel Shape: torch.Size([1, 128, 217])
Generated Mel Shape: torch.Size([1, 128, 165]), Reference Mel Shape: torch.Size([1, 128, 165])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 165])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 165])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 165])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 165])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 428/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8986/00003.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8986/00003.wav
Generated Mel Shape: torch.Size([1, 128, 165]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 429/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8988/00052.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8988/00052.wav
Generated Mel Shape: torch.Size([1, 128, 151]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 430/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8988/00053.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8988/00053.wav
Generated Mel Shape: torch.Size([1, 128, 144]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 144]), Reference Mel Shape: torch.Size([1, 128, 144])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 144])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 144])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 144])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 144])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 431/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8989/00004.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8989/00004.wav
Generated Mel Shape: torch.Size([1, 128, 157]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 157]), Reference Mel Shape: torch.Size([1, 128, 157])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 157])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 157])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 79])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 157])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 157])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 79])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 432/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8991/00029.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8991/00029.wav
Generated Mel Shape: torch.Size([1, 128, 118]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 118]), Reference Mel Shape: torch.Size([1, 128, 118])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 118])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 118])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 118])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 118])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 433/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8992/00022.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8992/00022.wav
Generated Mel Shape: torch.Size([1, 128, 117]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 117]), Reference Mel Shape: torch.Size([1, 128, 117])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 117])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 117])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 434/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8993/00029.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8993/00029.wav
Generated Mel Shape: torch.Size([1, 128, 117]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 117]), Reference Mel Shape: torch.Size([1, 128, 117])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 117])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 117])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 435/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8996/00065.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8996/00065.wav
Generated Mel Shape: torch.Size([1, 128, 258]), Reference Mel Shape: torch.Size([1, 128, 249])
Generated Mel Shape: torch.Size([1, 128, 249]), Reference Mel Shape: torch.Size([1, 128, 249])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 249])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 249])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 125])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 63])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 249])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 249])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 125])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 63])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])

[Processing Pair 436/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8996/00068.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8996/00068.wav
Generated Mel Shape: torch.Size([1, 128, 139]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 139]), Reference Mel Shape: torch.Size([1, 128, 139])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 139])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 139])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 139])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 139])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 437/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8997/00074.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8997/00074.wav
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 131])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 438/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8997/00077.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8997/00077.wav
Generated Mel Shape: torch.Size([1, 128, 160]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 160]), Reference Mel Shape: torch.Size([1, 128, 160])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 439/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8998/00003.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8998/00003.wav
Generated Mel Shape: torch.Size([1, 128, 188]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 172]), Reference Mel Shape: torch.Size([1, 128, 172])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 440/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk8999/00004.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk8999/00004.wav
Generated Mel Shape: torch.Size([1, 128, 158]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 158]), Reference Mel Shape: torch.Size([1, 128, 158])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 158])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 158])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 79])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 158])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 158])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 79])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 441/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9000/00021.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9000/00021.wav
Generated Mel Shape: torch.Size([1, 128, 167]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 167]), Reference Mel Shape: torch.Size([1, 128, 167])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 167])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 167])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 84])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 167])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 167])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 84])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 442/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9002/00046.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9002/00046.wav
Generated Mel Shape: torch.Size([1, 128, 105]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 105]), Reference Mel Shape: torch.Size([1, 128, 105])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 105])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 105])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 105])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 105])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 443/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9005/00008.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9005/00008.wav
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 131])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 444/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9006/00021.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9006/00021.wav
Generated Mel Shape: torch.Size([1, 128, 178]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 445/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9007/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9007/00011.wav
Generated Mel Shape: torch.Size([1, 128, 169]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 169]), Reference Mel Shape: torch.Size([1, 128, 169])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 169])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 169])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 85])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 169])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 169])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 85])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 446/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9008/00022.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9008/00022.wav
Generated Mel Shape: torch.Size([1, 128, 123]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 123]), Reference Mel Shape: torch.Size([1, 128, 123])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 123])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 123])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 62])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 123])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 123])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 62])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 447/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9009/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9009/00006.wav
Generated Mel Shape: torch.Size([1, 128, 277]), Reference Mel Shape: torch.Size([1, 128, 332])
Generated Mel Shape: torch.Size([1, 128, 277]), Reference Mel Shape: torch.Size([1, 128, 277])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 277])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 277])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 139])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 35])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4480])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 277])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 277])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 139])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 35])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 35])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4480])

[Processing Pair 448/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9010/00019.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9010/00019.wav
Generated Mel Shape: torch.Size([1, 128, 239]), Reference Mel Shape: torch.Size([1, 128, 249])
Generated Mel Shape: torch.Size([1, 128, 239]), Reference Mel Shape: torch.Size([1, 128, 239])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 239])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 239])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 120])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 30])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3840])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 239])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 239])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 120])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 30])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3840])

[Processing Pair 449/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9011/00023.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9011/00023.wav
Generated Mel Shape: torch.Size([1, 128, 105]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 105]), Reference Mel Shape: torch.Size([1, 128, 105])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 105])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 105])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 105])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 105])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 450/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9012/00007.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9012/00007.wav
Generated Mel Shape: torch.Size([1, 128, 269]), Reference Mel Shape: torch.Size([1, 128, 281])
Generated Mel Shape: torch.Size([1, 128, 269]), Reference Mel Shape: torch.Size([1, 128, 269])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 269])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 269])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 135])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 68])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 34])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 34])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4352])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 269])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 269])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 135])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 68])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 34])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 34])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4352])

[Processing Pair 451/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9013/00034.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9013/00034.wav
Generated Mel Shape: torch.Size([1, 128, 139]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 139]), Reference Mel Shape: torch.Size([1, 128, 139])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 139])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 139])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 139])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 139])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 452/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9016/00102.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9016/00102.wav
Generated Mel Shape: torch.Size([1, 128, 148]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 148]), Reference Mel Shape: torch.Size([1, 128, 148])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 148])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 148])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 148])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 148])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 453/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9017/00049.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9017/00049.wav
Generated Mel Shape: torch.Size([1, 128, 233]), Reference Mel Shape: torch.Size([1, 128, 256])
Generated Mel Shape: torch.Size([1, 128, 233]), Reference Mel Shape: torch.Size([1, 128, 233])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 233])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 233])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 30])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3840])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 233])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 233])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 30])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3840])

[Processing Pair 454/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9018/00110.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9018/00110.wav
Generated Mel Shape: torch.Size([1, 128, 173]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 173]), Reference Mel Shape: torch.Size([1, 128, 173])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 173])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 173])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 87])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 173])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 173])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 87])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 455/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9019/00010.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9019/00010.wav
Generated Mel Shape: torch.Size([1, 128, 162]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 456/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9022/00032.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9022/00032.wav
Generated Mel Shape: torch.Size([1, 128, 137]), Reference Mel Shape: torch.Size([1, 128, 134])
Generated Mel Shape: torch.Size([1, 128, 134]), Reference Mel Shape: torch.Size([1, 128, 134])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 457/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9027/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9027/00011.wav
Generated Mel Shape: torch.Size([1, 128, 157]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 147]), Reference Mel Shape: torch.Size([1, 128, 147])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 147])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 147])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 458/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9028/00005.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9028/00005.wav
Generated Mel Shape: torch.Size([1, 128, 193]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 193]), Reference Mel Shape: torch.Size([1, 128, 193])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 193])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 193])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 97])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 49])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 193])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 193])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 97])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 49])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])

[Processing Pair 459/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9029/00007.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9029/00007.wav
Generated Mel Shape: torch.Size([1, 128, 294]), Reference Mel Shape: torch.Size([1, 128, 320])
Generated Mel Shape: torch.Size([1, 128, 294]), Reference Mel Shape: torch.Size([1, 128, 294])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 294])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 294])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 37])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 37])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4736])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 294])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 294])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 37])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 37])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4736])

[Processing Pair 460/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9029/00015.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9029/00015.wav
Generated Mel Shape: torch.Size([1, 128, 179]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 172]), Reference Mel Shape: torch.Size([1, 128, 172])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 461/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9031/00074.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9031/00074.wav
Generated Mel Shape: torch.Size([1, 128, 122]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 122]), Reference Mel Shape: torch.Size([1, 128, 122])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 122])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 122])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 122])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 122])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 462/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9031/00129.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9031/00129.wav
Generated Mel Shape: torch.Size([1, 128, 143]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 143]), Reference Mel Shape: torch.Size([1, 128, 143])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 143])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 143])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 143])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 143])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 463/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9031/00130.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9031/00130.wav
Generated Mel Shape: torch.Size([1, 128, 132]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 132]), Reference Mel Shape: torch.Size([1, 128, 132])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 132])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 132])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 132])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 132])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 464/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9032/00062.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9032/00062.wav
Generated Mel Shape: torch.Size([1, 128, 178]), Reference Mel Shape: torch.Size([1, 128, 243])
Generated Mel Shape: torch.Size([1, 128, 178]), Reference Mel Shape: torch.Size([1, 128, 178])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 178])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 178])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 178])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 178])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 465/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9032/00070.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9032/00070.wav
Generated Mel Shape: torch.Size([1, 128, 142]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 142]), Reference Mel Shape: torch.Size([1, 128, 142])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 142])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 142])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 142])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 142])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 466/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9032/00083.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9032/00083.wav
Generated Mel Shape: torch.Size([1, 128, 138]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 138]), Reference Mel Shape: torch.Size([1, 128, 138])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 138])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 138])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 69])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 138])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 138])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 69])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 467/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9032/00118.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9032/00118.wav
Generated Mel Shape: torch.Size([1, 128, 145]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 145]), Reference Mel Shape: torch.Size([1, 128, 145])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 145])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 145])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 145])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 145])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 468/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9032/00163.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9032/00163.wav
Generated Mel Shape: torch.Size([1, 128, 150]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 150]), Reference Mel Shape: torch.Size([1, 128, 150])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 150])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 150])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 75])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 150])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 150])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 75])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 469/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9033/00105.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9033/00105.wav
Generated Mel Shape: torch.Size([1, 128, 232]), Reference Mel Shape: torch.Size([1, 128, 281])
Generated Mel Shape: torch.Size([1, 128, 232]), Reference Mel Shape: torch.Size([1, 128, 232])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 232])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 232])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 232])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 232])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])

[Processing Pair 470/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9034/00103.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9034/00103.wav
Generated Mel Shape: torch.Size([1, 128, 188]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 188]), Reference Mel Shape: torch.Size([1, 128, 188])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 188])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 188])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 94])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 188])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 188])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 94])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 471/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9036/00160.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9036/00160.wav
Generated Mel Shape: torch.Size([1, 128, 517]), Reference Mel Shape: torch.Size([1, 128, 576])
Generated Mel Shape: torch.Size([1, 128, 517]), Reference Mel Shape: torch.Size([1, 128, 517])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 517])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 517])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 259])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 130])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 65])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 65])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 8320])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 517])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 517])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 259])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 130])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 65])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 65])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 8320])

[Processing Pair 472/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9036/00188.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9036/00188.wav
Generated Mel Shape: torch.Size([1, 128, 160]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 160]), Reference Mel Shape: torch.Size([1, 128, 160])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 473/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9037/00005.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9037/00005.wav
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 161])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 161])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 161])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 161])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 161])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 474/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9039/00015.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9039/00015.wav
Generated Mel Shape: torch.Size([1, 128, 165]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 165]), Reference Mel Shape: torch.Size([1, 128, 165])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 165])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 165])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 165])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 165])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 475/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9040/00045.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9040/00045.wav
Generated Mel Shape: torch.Size([1, 128, 200]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 192]), Reference Mel Shape: torch.Size([1, 128, 192])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 192])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 192])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 192])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 192])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 476/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9040/00048.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9040/00048.wav
Generated Mel Shape: torch.Size([1, 128, 224]), Reference Mel Shape: torch.Size([1, 128, 320])
Generated Mel Shape: torch.Size([1, 128, 224]), Reference Mel Shape: torch.Size([1, 128, 224])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 224])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 224])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 224])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 224])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])

[Processing Pair 477/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9041/00025.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9041/00025.wav
Generated Mel Shape: torch.Size([1, 128, 210]), Reference Mel Shape: torch.Size([1, 128, 249])
Generated Mel Shape: torch.Size([1, 128, 210]), Reference Mel Shape: torch.Size([1, 128, 210])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 210])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 210])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 105])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 210])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 210])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 105])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])

[Processing Pair 478/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9042/00029.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9042/00029.wav
Generated Mel Shape: torch.Size([1, 128, 216]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 216]), Reference Mel Shape: torch.Size([1, 128, 216])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 216])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 216])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 108])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 216])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 216])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 108])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])

[Processing Pair 479/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9044/00076.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9044/00076.wav
Generated Mel Shape: torch.Size([1, 128, 205]), Reference Mel Shape: torch.Size([1, 128, 243])
Generated Mel Shape: torch.Size([1, 128, 205]), Reference Mel Shape: torch.Size([1, 128, 205])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 205])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 205])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 103])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 205])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 205])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 103])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])

[Processing Pair 480/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9044/00128.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9044/00128.wav
Generated Mel Shape: torch.Size([1, 128, 222]), Reference Mel Shape: torch.Size([1, 128, 198])
Generated Mel Shape: torch.Size([1, 128, 198]), Reference Mel Shape: torch.Size([1, 128, 198])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 198])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 198])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 99])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 198])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 198])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 99])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])

[Processing Pair 481/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9045/00183.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9045/00183.wav
Generated Mel Shape: torch.Size([1, 128, 142]), Reference Mel Shape: torch.Size([1, 128, 134])
Generated Mel Shape: torch.Size([1, 128, 134]), Reference Mel Shape: torch.Size([1, 128, 134])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 482/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9046/00018.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9046/00018.wav
Generated Mel Shape: torch.Size([1, 128, 200]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 200]), Reference Mel Shape: torch.Size([1, 128, 200])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 200])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 200])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 100])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 200])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 200])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 100])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])

[Processing Pair 483/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9047/00008.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9047/00008.wav
Generated Mel Shape: torch.Size([1, 128, 159]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 484/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9047/00015.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9047/00015.wav
Generated Mel Shape: torch.Size([1, 128, 301]), Reference Mel Shape: torch.Size([1, 128, 320])
Generated Mel Shape: torch.Size([1, 128, 301]), Reference Mel Shape: torch.Size([1, 128, 301])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 301])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 301])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 151])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 38])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4864])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 301])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 301])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 151])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 38])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 38])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4864])

[Processing Pair 485/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9047/00032.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9047/00032.wav
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 211])
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 161])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 161])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 161])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 161])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 161])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 486/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9047/00056.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9047/00056.wav
Generated Mel Shape: torch.Size([1, 128, 529]), Reference Mel Shape: torch.Size([1, 128, 454])
Generated Mel Shape: torch.Size([1, 128, 454]), Reference Mel Shape: torch.Size([1, 128, 454])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 454])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 454])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 227])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 114])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 57])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 57])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 7296])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 454])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 454])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 227])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 114])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 57])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 57])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 7296])

[Processing Pair 487/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9047/00058.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9047/00058.wav
Generated Mel Shape: torch.Size([1, 128, 232]), Reference Mel Shape: torch.Size([1, 128, 268])
Generated Mel Shape: torch.Size([1, 128, 232]), Reference Mel Shape: torch.Size([1, 128, 232])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 232])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 232])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 232])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 232])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])

[Processing Pair 488/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9050/00021.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9050/00021.wav
Generated Mel Shape: torch.Size([1, 128, 164]), Reference Mel Shape: torch.Size([1, 128, 217])
Generated Mel Shape: torch.Size([1, 128, 164]), Reference Mel Shape: torch.Size([1, 128, 164])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 164])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 164])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 164])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 164])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 489/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9051/00030.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9051/00030.wav
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 490/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9052/00062.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9052/00062.wav
Generated Mel Shape: torch.Size([1, 128, 127]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 127]), Reference Mel Shape: torch.Size([1, 128, 127])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 127])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 127])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 127])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 127])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 491/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9054/00003.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9054/00003.wav
Generated Mel Shape: torch.Size([1, 128, 178]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 492/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9055/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9055/00002.wav
Generated Mel Shape: torch.Size([1, 128, 157]), Reference Mel Shape: torch.Size([1, 128, 198])
Generated Mel Shape: torch.Size([1, 128, 157]), Reference Mel Shape: torch.Size([1, 128, 157])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 157])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 157])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 79])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 157])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 157])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 79])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 493/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9056/00033.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9056/00033.wav
Generated Mel Shape: torch.Size([1, 128, 207]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 494/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9056/00037.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9056/00037.wav
Generated Mel Shape: torch.Size([1, 128, 276]), Reference Mel Shape: torch.Size([1, 128, 243])
Generated Mel Shape: torch.Size([1, 128, 243]), Reference Mel Shape: torch.Size([1, 128, 243])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 243])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 243])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 122])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 31])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 31])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3968])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 243])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 243])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 122])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 31])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 31])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3968])

[Processing Pair 495/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9056/00040.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9056/00040.wav
Generated Mel Shape: torch.Size([1, 128, 162]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 162]), Reference Mel Shape: torch.Size([1, 128, 162])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 162])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 162])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 162])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 162])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 496/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9058/00007.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9058/00007.wav
Generated Mel Shape: torch.Size([1, 128, 101]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 101]), Reference Mel Shape: torch.Size([1, 128, 101])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 101])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 101])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])

[Processing Pair 497/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9059/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9059/00006.wav
Generated Mel Shape: torch.Size([1, 128, 230]), Reference Mel Shape: torch.Size([1, 128, 281])
Generated Mel Shape: torch.Size([1, 128, 230]), Reference Mel Shape: torch.Size([1, 128, 230])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 230])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 230])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 115])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 230])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 230])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 115])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])

[Processing Pair 498/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9060/00007.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9060/00007.wav
Generated Mel Shape: torch.Size([1, 128, 103]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 103]), Reference Mel Shape: torch.Size([1, 128, 103])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 103])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 103])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 103])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 103])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])

[Processing Pair 499/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9061/00005.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9061/00005.wav
Generated Mel Shape: torch.Size([1, 128, 87]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 87]), Reference Mel Shape: torch.Size([1, 128, 87])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 87])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 87])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 11])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1408])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 87])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 87])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 11])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1408])

[Processing Pair 500/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9061/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9061/00006.wav
Generated Mel Shape: torch.Size([1, 128, 129]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 129]), Reference Mel Shape: torch.Size([1, 128, 129])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 129])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 129])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 129])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 129])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 501/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9063/00005.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9063/00005.wav
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 502/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9066/00007.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9066/00007.wav
Generated Mel Shape: torch.Size([1, 128, 142]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 503/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9067/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9067/00006.wav
Generated Mel Shape: torch.Size([1, 128, 132]), Reference Mel Shape: torch.Size([1, 128, 134])
Generated Mel Shape: torch.Size([1, 128, 132]), Reference Mel Shape: torch.Size([1, 128, 132])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 132])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 132])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 132])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 132])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 504/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9067/00016.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9067/00016.wav
Generated Mel Shape: torch.Size([1, 128, 171]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 171]), Reference Mel Shape: torch.Size([1, 128, 171])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 171])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 171])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 171])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 171])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 505/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9068/00013.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9068/00013.wav
Generated Mel Shape: torch.Size([1, 128, 122]), Reference Mel Shape: torch.Size([1, 128, 134])
Generated Mel Shape: torch.Size([1, 128, 122]), Reference Mel Shape: torch.Size([1, 128, 122])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 122])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 122])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 122])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 122])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 506/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9070/00032.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9070/00032.wav
Generated Mel Shape: torch.Size([1, 128, 138]), Reference Mel Shape: torch.Size([1, 128, 198])
Generated Mel Shape: torch.Size([1, 128, 138]), Reference Mel Shape: torch.Size([1, 128, 138])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 138])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 138])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 69])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 138])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 138])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 69])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 507/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9070/00053.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9070/00053.wav
Generated Mel Shape: torch.Size([1, 128, 216]), Reference Mel Shape: torch.Size([1, 128, 281])
Generated Mel Shape: torch.Size([1, 128, 216]), Reference Mel Shape: torch.Size([1, 128, 216])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 216])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 216])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 108])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 216])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 216])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 108])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])

[Processing Pair 508/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9071/00099.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9071/00099.wav
Generated Mel Shape: torch.Size([1, 128, 139]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 139]), Reference Mel Shape: torch.Size([1, 128, 139])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 139])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 139])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 139])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 139])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 509/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9073/00179.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9073/00179.wav
Generated Mel Shape: torch.Size([1, 128, 231]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 204]), Reference Mel Shape: torch.Size([1, 128, 204])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 204])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 204])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 204])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 204])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])

[Processing Pair 510/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9073/00181.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9073/00181.wav
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 161])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 161])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 161])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 161])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 161])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 81])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 511/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9073/00182.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9073/00182.wav
Generated Mel Shape: torch.Size([1, 128, 310]), Reference Mel Shape: torch.Size([1, 128, 326])
Generated Mel Shape: torch.Size([1, 128, 310]), Reference Mel Shape: torch.Size([1, 128, 310])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 310])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 310])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 155])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 78])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 39])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 39])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4992])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 310])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 310])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 155])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 78])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 39])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 39])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4992])

[Processing Pair 512/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9074/00012.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9074/00012.wav
Generated Mel Shape: torch.Size([1, 128, 210]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 179]), Reference Mel Shape: torch.Size([1, 128, 179])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 179])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 179])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 179])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 179])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 513/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9075/00029.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9075/00029.wav
Generated Mel Shape: torch.Size([1, 128, 263]), Reference Mel Shape: torch.Size([1, 128, 320])
Generated Mel Shape: torch.Size([1, 128, 263]), Reference Mel Shape: torch.Size([1, 128, 263])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 263])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 263])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 132])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 33])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4224])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 263])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 263])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 132])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 33])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4224])

[Processing Pair 514/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9077/00016.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9077/00016.wav
Generated Mel Shape: torch.Size([1, 128, 128]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 128]), Reference Mel Shape: torch.Size([1, 128, 128])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 128])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 128])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 515/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9078/00018.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9078/00018.wav
Generated Mel Shape: torch.Size([1, 128, 466]), Reference Mel Shape: torch.Size([1, 128, 486])
Generated Mel Shape: torch.Size([1, 128, 466]), Reference Mel Shape: torch.Size([1, 128, 466])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 466])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 466])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 233])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 59])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 59])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 7552])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 466])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 466])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 233])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 59])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 59])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 7552])

[Processing Pair 516/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9079/00003.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9079/00003.wav
Generated Mel Shape: torch.Size([1, 128, 171]), Reference Mel Shape: torch.Size([1, 128, 211])
Generated Mel Shape: torch.Size([1, 128, 171]), Reference Mel Shape: torch.Size([1, 128, 171])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 171])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 171])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 171])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 171])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 517/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9079/00012.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9079/00012.wav
Generated Mel Shape: torch.Size([1, 128, 111]), Reference Mel Shape: torch.Size([1, 128, 198])
Generated Mel Shape: torch.Size([1, 128, 111]), Reference Mel Shape: torch.Size([1, 128, 111])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 111])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 111])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 111])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 111])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 518/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9079/00016.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9079/00016.wav
Generated Mel Shape: torch.Size([1, 128, 165]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 519/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9080/00005.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9080/00005.wav
Generated Mel Shape: torch.Size([1, 128, 117]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 117]), Reference Mel Shape: torch.Size([1, 128, 117])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 117])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 117])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 520/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9081/00010.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9081/00010.wav
Generated Mel Shape: torch.Size([1, 128, 194]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 194]), Reference Mel Shape: torch.Size([1, 128, 194])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 194])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 194])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 97])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 49])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 194])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 194])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 97])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 49])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])

[Processing Pair 521/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9082/00010.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9082/00010.wav
Generated Mel Shape: torch.Size([1, 128, 145]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 145]), Reference Mel Shape: torch.Size([1, 128, 145])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 145])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 145])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 145])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 145])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 522/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9083/00001.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9083/00001.wav
Generated Mel Shape: torch.Size([1, 128, 127]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 127]), Reference Mel Shape: torch.Size([1, 128, 127])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 127])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 127])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 127])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 127])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 523/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9084/00012.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9084/00012.wav
Generated Mel Shape: torch.Size([1, 128, 152]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 524/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9088/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9088/00002.wav
Generated Mel Shape: torch.Size([1, 128, 281]), Reference Mel Shape: torch.Size([1, 128, 256])
Generated Mel Shape: torch.Size([1, 128, 256]), Reference Mel Shape: torch.Size([1, 128, 256])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 256])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 256])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 256])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 256])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])

[Processing Pair 525/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9089/00029.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9089/00029.wav
Generated Mel Shape: torch.Size([1, 128, 168]), Reference Mel Shape: torch.Size([1, 128, 217])
Generated Mel Shape: torch.Size([1, 128, 168]), Reference Mel Shape: torch.Size([1, 128, 168])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 168])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 168])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 84])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 168])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 168])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 84])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 526/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9090/00004.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9090/00004.wav
Generated Mel Shape: torch.Size([1, 128, 222]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 185]), Reference Mel Shape: torch.Size([1, 128, 185])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 185])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 185])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 93])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 185])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 185])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 93])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 527/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9090/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9090/00011.wav
Generated Mel Shape: torch.Size([1, 128, 221]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 192]), Reference Mel Shape: torch.Size([1, 128, 192])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 192])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 192])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 192])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 192])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 528/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9090/00015.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9090/00015.wav
Generated Mel Shape: torch.Size([1, 128, 156]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 529/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9091/00008.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9091/00008.wav
Generated Mel Shape: torch.Size([1, 128, 149]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 530/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9092/00001.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9092/00001.wav
Generated Mel Shape: torch.Size([1, 128, 141]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 141]), Reference Mel Shape: torch.Size([1, 128, 141])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 141])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 141])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 531/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9096/00003.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9096/00003.wav
Generated Mel Shape: torch.Size([1, 128, 128]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 128]), Reference Mel Shape: torch.Size([1, 128, 128])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 128])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 128])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 532/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9097/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9097/00002.wav
Generated Mel Shape: torch.Size([1, 128, 185]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 166]), Reference Mel Shape: torch.Size([1, 128, 166])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 166])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 166])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 533/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9097/00004.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9097/00004.wav
Generated Mel Shape: torch.Size([1, 128, 357]), Reference Mel Shape: torch.Size([1, 128, 390])
Generated Mel Shape: torch.Size([1, 128, 357]), Reference Mel Shape: torch.Size([1, 128, 357])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 357])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 357])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 179])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 45])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5760])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 357])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 357])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 179])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 90])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 45])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 45])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5760])

[Processing Pair 534/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9097/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9097/00006.wav
Generated Mel Shape: torch.Size([1, 128, 424]), Reference Mel Shape: torch.Size([1, 128, 441])
Generated Mel Shape: torch.Size([1, 128, 424]), Reference Mel Shape: torch.Size([1, 128, 424])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 424])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 424])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 212])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 106])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 53])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 53])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 6784])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 424])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 424])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 212])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 106])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 53])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 53])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 6784])

[Processing Pair 535/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9098/00023.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9098/00023.wav
Generated Mel Shape: torch.Size([1, 128, 143]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 143]), Reference Mel Shape: torch.Size([1, 128, 143])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 143])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 143])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 143])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 143])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 536/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9099/00025.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9099/00025.wav
Generated Mel Shape: torch.Size([1, 128, 155]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 537/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9101/00013.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9101/00013.wav
Generated Mel Shape: torch.Size([1, 128, 180]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 147]), Reference Mel Shape: torch.Size([1, 128, 147])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 147])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 147])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 538/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9102/00004.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9102/00004.wav
Generated Mel Shape: torch.Size([1, 128, 94]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 94]), Reference Mel Shape: torch.Size([1, 128, 94])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 94])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 94])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 94])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 94])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])

[Processing Pair 539/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9104/00012.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9104/00012.wav
Generated Mel Shape: torch.Size([1, 128, 152]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 152]), Reference Mel Shape: torch.Size([1, 128, 152])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 152])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 152])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 152])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 152])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 540/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9105/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9105/00006.wav
Generated Mel Shape: torch.Size([1, 128, 128]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 128]), Reference Mel Shape: torch.Size([1, 128, 128])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 128])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 128])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 541/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9106/00010.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9106/00010.wav
Generated Mel Shape: torch.Size([1, 128, 148]), Reference Mel Shape: torch.Size([1, 128, 198])
Generated Mel Shape: torch.Size([1, 128, 148]), Reference Mel Shape: torch.Size([1, 128, 148])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 148])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 148])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 148])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 148])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 542/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9107/00012.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9107/00012.wav
Generated Mel Shape: torch.Size([1, 128, 168]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 168]), Reference Mel Shape: torch.Size([1, 128, 168])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 168])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 168])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 84])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 168])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 168])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 84])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 543/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9107/00013.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9107/00013.wav
Generated Mel Shape: torch.Size([1, 128, 107]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 107]), Reference Mel Shape: torch.Size([1, 128, 107])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 107])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 107])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 107])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 107])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 544/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9108/00025.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9108/00025.wav
Generated Mel Shape: torch.Size([1, 128, 188]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 172]), Reference Mel Shape: torch.Size([1, 128, 172])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 545/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9110/00005.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9110/00005.wav
Generated Mel Shape: torch.Size([1, 128, 146]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 146]), Reference Mel Shape: torch.Size([1, 128, 146])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 146])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 146])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 146])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 146])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 546/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9111/00018.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9111/00018.wav
Generated Mel Shape: torch.Size([1, 128, 141]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 141]), Reference Mel Shape: torch.Size([1, 128, 141])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 141])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 141])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 547/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9114/00092.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9114/00092.wav
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 131]), Reference Mel Shape: torch.Size([1, 128, 131])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 131])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 131])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 66])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 548/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9115/00110.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9115/00110.wav
Generated Mel Shape: torch.Size([1, 128, 141]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 141]), Reference Mel Shape: torch.Size([1, 128, 141])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 141])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 141])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 549/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9116/00132.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9116/00132.wav
Generated Mel Shape: torch.Size([1, 128, 169]), Reference Mel Shape: torch.Size([1, 128, 198])
Generated Mel Shape: torch.Size([1, 128, 169]), Reference Mel Shape: torch.Size([1, 128, 169])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 169])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 169])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 85])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 169])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 169])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 85])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 550/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9117/00156.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9117/00156.wav
Generated Mel Shape: torch.Size([1, 128, 116]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 116]), Reference Mel Shape: torch.Size([1, 128, 116])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 116])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 116])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 551/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9117/00158.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9117/00158.wav
Generated Mel Shape: torch.Size([1, 128, 198]), Reference Mel Shape: torch.Size([1, 128, 230])
Generated Mel Shape: torch.Size([1, 128, 198]), Reference Mel Shape: torch.Size([1, 128, 198])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 198])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 198])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 99])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 198])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 198])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 99])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])

[Processing Pair 552/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9117/00172.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9117/00172.wav
Generated Mel Shape: torch.Size([1, 128, 151]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 151]), Reference Mel Shape: torch.Size([1, 128, 151])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 151])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 151])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 151])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 151])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 553/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9118/00174.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9118/00174.wav
Generated Mel Shape: torch.Size([1, 128, 120]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 120]), Reference Mel Shape: torch.Size([1, 128, 120])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 120])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 120])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 120])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 120])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 554/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9121/00213.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9121/00213.wav
Generated Mel Shape: torch.Size([1, 128, 135]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 135]), Reference Mel Shape: torch.Size([1, 128, 135])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 135])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 135])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 68])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 135])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 135])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 68])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 555/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9122/00014.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9122/00014.wav
Generated Mel Shape: torch.Size([1, 128, 121]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 121]), Reference Mel Shape: torch.Size([1, 128, 121])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 121])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 121])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 121])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 121])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 556/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9124/00015.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9124/00015.wav
Generated Mel Shape: torch.Size([1, 128, 254]), Reference Mel Shape: torch.Size([1, 128, 332])
Generated Mel Shape: torch.Size([1, 128, 254]), Reference Mel Shape: torch.Size([1, 128, 254])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 254])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 254])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 127])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 254])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 254])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 127])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])

[Processing Pair 557/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9131/00008.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9131/00008.wav
Generated Mel Shape: torch.Size([1, 128, 292]), Reference Mel Shape: torch.Size([1, 128, 288])
Generated Mel Shape: torch.Size([1, 128, 288]), Reference Mel Shape: torch.Size([1, 128, 288])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 288])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 288])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 144])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 36])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 36])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4608])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 288])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 288])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 144])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 36])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 36])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4608])

[Processing Pair 558/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9133/00005.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9133/00005.wav
Generated Mel Shape: torch.Size([1, 128, 151]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 151]), Reference Mel Shape: torch.Size([1, 128, 151])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 151])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 151])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 151])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 151])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 559/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9139/00073.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9139/00073.wav
Generated Mel Shape: torch.Size([1, 128, 194]), Reference Mel Shape: torch.Size([1, 128, 217])
Generated Mel Shape: torch.Size([1, 128, 194]), Reference Mel Shape: torch.Size([1, 128, 194])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 194])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 194])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 97])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 49])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 194])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 194])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 97])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 49])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])

[Processing Pair 560/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9140/00163.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9140/00163.wav
Generated Mel Shape: torch.Size([1, 128, 116]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 116]), Reference Mel Shape: torch.Size([1, 128, 116])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 116])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 116])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 561/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9141/00144.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9141/00144.wav
Generated Mel Shape: torch.Size([1, 128, 149]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 149]), Reference Mel Shape: torch.Size([1, 128, 149])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 149])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 149])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 75])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 149])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 149])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 75])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 562/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9142/00158.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9142/00158.wav
Generated Mel Shape: torch.Size([1, 128, 238]), Reference Mel Shape: torch.Size([1, 128, 262])
Generated Mel Shape: torch.Size([1, 128, 238]), Reference Mel Shape: torch.Size([1, 128, 238])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 238])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 238])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 119])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 30])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3840])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 238])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 238])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 119])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 30])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 30])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3840])

[Processing Pair 563/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9144/00010.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9144/00010.wav
Generated Mel Shape: torch.Size([1, 128, 173]), Reference Mel Shape: torch.Size([1, 128, 217])
Generated Mel Shape: torch.Size([1, 128, 173]), Reference Mel Shape: torch.Size([1, 128, 173])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 173])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 173])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 87])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 173])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 173])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 87])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 44])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 564/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9147/00003.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9147/00003.wav
Generated Mel Shape: torch.Size([1, 128, 146]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 565/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9147/00005.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9147/00005.wav
Generated Mel Shape: torch.Size([1, 128, 135]), Reference Mel Shape: torch.Size([1, 128, 134])
Generated Mel Shape: torch.Size([1, 128, 134]), Reference Mel Shape: torch.Size([1, 128, 134])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 566/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9149/00013.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9149/00013.wav
Generated Mel Shape: torch.Size([1, 128, 313]), Reference Mel Shape: torch.Size([1, 128, 268])
Generated Mel Shape: torch.Size([1, 128, 268]), Reference Mel Shape: torch.Size([1, 128, 268])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 268])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 268])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 34])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 34])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4352])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 268])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 268])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 34])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 34])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4352])

[Processing Pair 567/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9150/00016.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9150/00016.wav
Generated Mel Shape: torch.Size([1, 128, 147]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 568/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9151/00016.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9151/00016.wav
Generated Mel Shape: torch.Size([1, 128, 177]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 160]), Reference Mel Shape: torch.Size([1, 128, 160])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 569/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9152/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9152/00011.wav
Generated Mel Shape: torch.Size([1, 128, 238]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 224]), Reference Mel Shape: torch.Size([1, 128, 224])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 224])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 224])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 224])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 224])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])

[Processing Pair 570/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9152/00013.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9152/00013.wav
Generated Mel Shape: torch.Size([1, 128, 113]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 113]), Reference Mel Shape: torch.Size([1, 128, 113])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 113])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 113])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 113])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 113])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 571/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9152/00014.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9152/00014.wav
Generated Mel Shape: torch.Size([1, 128, 125]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 125]), Reference Mel Shape: torch.Size([1, 128, 125])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 125])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 125])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 63])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 125])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 125])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 63])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 572/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9153/00017.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9153/00017.wav
Generated Mel Shape: torch.Size([1, 128, 291]), Reference Mel Shape: torch.Size([1, 128, 384])
Generated Mel Shape: torch.Size([1, 128, 291]), Reference Mel Shape: torch.Size([1, 128, 291])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 291])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 291])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 146])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 37])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 37])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4736])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 291])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 291])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 146])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 73])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 37])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 37])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4736])

[Processing Pair 573/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9154/00021.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9154/00021.wav
Generated Mel Shape: torch.Size([1, 128, 203]), Reference Mel Shape: torch.Size([1, 128, 249])
Generated Mel Shape: torch.Size([1, 128, 203]), Reference Mel Shape: torch.Size([1, 128, 203])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 203])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 203])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 203])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 203])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])

[Processing Pair 574/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9154/00030.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9154/00030.wav
Generated Mel Shape: torch.Size([1, 128, 159]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 159]), Reference Mel Shape: torch.Size([1, 128, 159])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 159])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 159])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 159])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 159])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 575/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9155/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9155/00006.wav
Generated Mel Shape: torch.Size([1, 128, 248]), Reference Mel Shape: torch.Size([1, 128, 256])
Generated Mel Shape: torch.Size([1, 128, 248]), Reference Mel Shape: torch.Size([1, 128, 248])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 248])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 248])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 124])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 62])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 31])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 31])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3968])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 248])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 248])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 124])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 62])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 31])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 31])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3968])

[Processing Pair 576/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9156/00018.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9156/00018.wav
Generated Mel Shape: torch.Size([1, 128, 199]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 199]), Reference Mel Shape: torch.Size([1, 128, 199])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 199])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 199])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 100])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 199])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 199])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 100])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])

[Processing Pair 577/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9157/00026.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9157/00026.wav
Generated Mel Shape: torch.Size([1, 128, 161]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 578/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9159/00019.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9159/00019.wav
Generated Mel Shape: torch.Size([1, 128, 113]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 113]), Reference Mel Shape: torch.Size([1, 128, 113])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 113])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 113])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 113])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 113])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 579/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9160/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9160/00006.wav
Generated Mel Shape: torch.Size([1, 128, 116]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 116]), Reference Mel Shape: torch.Size([1, 128, 116])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 116])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 116])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 580/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9161/00012.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9161/00012.wav
Generated Mel Shape: torch.Size([1, 128, 168]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 160]), Reference Mel Shape: torch.Size([1, 128, 160])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 581/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9162/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9162/00006.wav
Generated Mel Shape: torch.Size([1, 128, 133]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 133]), Reference Mel Shape: torch.Size([1, 128, 133])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 133])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 133])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 133])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 133])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 582/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9163/00017.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9163/00017.wav
Generated Mel Shape: torch.Size([1, 128, 144]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 144]), Reference Mel Shape: torch.Size([1, 128, 144])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 144])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 144])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 144])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 144])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 72])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 583/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9163/00018.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9163/00018.wav
Generated Mel Shape: torch.Size([1, 128, 122]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 122]), Reference Mel Shape: torch.Size([1, 128, 122])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 122])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 122])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 122])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 122])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 61])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 31])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 584/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9164/00004.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9164/00004.wav
Generated Mel Shape: torch.Size([1, 128, 110]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 110]), Reference Mel Shape: torch.Size([1, 128, 110])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 110])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 110])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 55])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 110])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 110])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 55])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 585/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9164/00010.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9164/00010.wav
Generated Mel Shape: torch.Size([1, 128, 105]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 105]), Reference Mel Shape: torch.Size([1, 128, 105])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 105])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 105])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 105])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 105])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 586/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9165/00015.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9165/00015.wav
Generated Mel Shape: torch.Size([1, 128, 199]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 192]), Reference Mel Shape: torch.Size([1, 128, 192])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 192])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 192])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 192])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 192])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 587/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9165/00028.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9165/00028.wav
Generated Mel Shape: torch.Size([1, 128, 257]), Reference Mel Shape: torch.Size([1, 128, 339])
Generated Mel Shape: torch.Size([1, 128, 257]), Reference Mel Shape: torch.Size([1, 128, 257])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 257])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 257])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 129])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 33])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4224])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 257])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 257])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 129])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 65])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 33])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 33])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4224])

[Processing Pair 588/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9166/00017.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9166/00017.wav
Generated Mel Shape: torch.Size([1, 128, 133]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 133]), Reference Mel Shape: torch.Size([1, 128, 133])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 133])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 133])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 133])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 133])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 589/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9166/00018.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9166/00018.wav
Generated Mel Shape: torch.Size([1, 128, 171]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 147]), Reference Mel Shape: torch.Size([1, 128, 147])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 147])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 147])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 590/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9167/00027.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9167/00027.wav
Generated Mel Shape: torch.Size([1, 128, 189]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 189]), Reference Mel Shape: torch.Size([1, 128, 189])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 189])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 189])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 95])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 189])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 189])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 95])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 591/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9169/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9169/00011.wav
Generated Mel Shape: torch.Size([1, 128, 111]), Reference Mel Shape: torch.Size([1, 128, 134])
Generated Mel Shape: torch.Size([1, 128, 111]), Reference Mel Shape: torch.Size([1, 128, 111])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 111])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 111])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 111])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 111])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 592/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9170/00019.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9170/00019.wav
Generated Mel Shape: torch.Size([1, 128, 96]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 96]), Reference Mel Shape: torch.Size([1, 128, 96])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 96])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 96])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 96])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])

[Processing Pair 593/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9172/00016.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9172/00016.wav
Generated Mel Shape: torch.Size([1, 128, 175]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 160]), Reference Mel Shape: torch.Size([1, 128, 160])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 160])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 160])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 80])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 40])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 594/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9172/00037.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9172/00037.wav
Generated Mel Shape: torch.Size([1, 128, 268]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 224]), Reference Mel Shape: torch.Size([1, 128, 224])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 224])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 224])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 224])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 224])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 28])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 28])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3584])

[Processing Pair 595/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9172/00057.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9172/00057.wav
Generated Mel Shape: torch.Size([1, 128, 223]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 204]), Reference Mel Shape: torch.Size([1, 128, 204])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 204])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 204])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 204])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 204])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])

[Processing Pair 596/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9172/00059.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9172/00059.wav
Generated Mel Shape: torch.Size([1, 128, 156]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 597/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9172/00105.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9172/00105.wav
Generated Mel Shape: torch.Size([1, 128, 151]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 598/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9178/00015.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9178/00015.wav
Generated Mel Shape: torch.Size([1, 128, 172]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 172]), Reference Mel Shape: torch.Size([1, 128, 172])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 172])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 172])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 599/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9180/00045.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9180/00045.wav
Generated Mel Shape: torch.Size([1, 128, 159]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 600/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9182/00015.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9182/00015.wav
Generated Mel Shape: torch.Size([1, 128, 109]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 109]), Reference Mel Shape: torch.Size([1, 128, 109])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 109])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 109])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 55])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 109])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 109])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 55])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 601/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9183/00004.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9183/00004.wav
Generated Mel Shape: torch.Size([1, 128, 215]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 204]), Reference Mel Shape: torch.Size([1, 128, 204])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 204])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 204])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 204])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 204])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])

[Processing Pair 602/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9184/00009.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9184/00009.wav
Generated Mel Shape: torch.Size([1, 128, 128]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 128]), Reference Mel Shape: torch.Size([1, 128, 128])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 128])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 128])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 16])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 16])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2048])

[Processing Pair 603/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9189/00017.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9189/00017.wav
Generated Mel Shape: torch.Size([1, 128, 181]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 166]), Reference Mel Shape: torch.Size([1, 128, 166])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 166])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 166])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 604/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9191/00003.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9191/00003.wav
Generated Mel Shape: torch.Size([1, 128, 187]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 187]), Reference Mel Shape: torch.Size([1, 128, 187])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 187])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 187])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 94])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 187])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 187])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 94])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 605/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9193/00018.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9193/00018.wav
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 166])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 606/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9194/00030.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9194/00030.wav
Generated Mel Shape: torch.Size([1, 128, 207]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 207]), Reference Mel Shape: torch.Size([1, 128, 207])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 207])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 207])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 104])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 207])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 207])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 104])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])

[Processing Pair 607/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9195/00007.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9195/00007.wav
Generated Mel Shape: torch.Size([1, 128, 171]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 171]), Reference Mel Shape: torch.Size([1, 128, 171])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 171])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 171])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 171])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 171])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 608/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9196/00027.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9196/00027.wav
Generated Mel Shape: torch.Size([1, 128, 383]), Reference Mel Shape: torch.Size([1, 128, 332])
Generated Mel Shape: torch.Size([1, 128, 332]), Reference Mel Shape: torch.Size([1, 128, 332])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 332])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 332])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 42])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 42])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5376])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 332])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 332])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 166])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 42])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 42])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 5376])

[Processing Pair 609/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9198/00049.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9198/00049.wav
Generated Mel Shape: torch.Size([1, 128, 92]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 92]), Reference Mel Shape: torch.Size([1, 128, 92])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 92])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 92])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 92])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 92])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 46])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])

[Processing Pair 610/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9201/00007.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9201/00007.wav
Generated Mel Shape: torch.Size([1, 128, 100]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 100]), Reference Mel Shape: torch.Size([1, 128, 100])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 100])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 100])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 100])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 100])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])

[Processing Pair 611/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9202/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9202/00011.wav
Generated Mel Shape: torch.Size([1, 128, 204]), Reference Mel Shape: torch.Size([1, 128, 249])
Generated Mel Shape: torch.Size([1, 128, 204]), Reference Mel Shape: torch.Size([1, 128, 204])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 204])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 204])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 204])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 204])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])

[Processing Pair 612/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9203/00020.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9203/00020.wav
Generated Mel Shape: torch.Size([1, 128, 286]), Reference Mel Shape: torch.Size([1, 128, 256])
Generated Mel Shape: torch.Size([1, 128, 256]), Reference Mel Shape: torch.Size([1, 128, 256])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 256])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 256])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 256])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 256])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 128])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 64])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])

[Processing Pair 613/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9204/00010.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9204/00010.wav
Generated Mel Shape: torch.Size([1, 128, 231]), Reference Mel Shape: torch.Size([1, 128, 236])
Generated Mel Shape: torch.Size([1, 128, 231]), Reference Mel Shape: torch.Size([1, 128, 231])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 231])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 231])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 231])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 231])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])

[Processing Pair 614/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9205/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9205/00006.wav
Generated Mel Shape: torch.Size([1, 128, 85]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 85]), Reference Mel Shape: torch.Size([1, 128, 85])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 85])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 85])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 11])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1408])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 85])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 85])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 11])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 11])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1408])

[Processing Pair 615/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9208/00020.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9208/00020.wav
Generated Mel Shape: torch.Size([1, 128, 111]), Reference Mel Shape: torch.Size([1, 128, 160])
Generated Mel Shape: torch.Size([1, 128, 111]), Reference Mel Shape: torch.Size([1, 128, 111])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 111])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 111])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 111])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 111])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 616/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9209/00003.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9209/00003.wav
Generated Mel Shape: torch.Size([1, 128, 141]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 141]), Reference Mel Shape: torch.Size([1, 128, 141])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 141])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 141])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 617/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9210/00013.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9210/00013.wav
Generated Mel Shape: torch.Size([1, 128, 113]), Reference Mel Shape: torch.Size([1, 128, 249])
Generated Mel Shape: torch.Size([1, 128, 113]), Reference Mel Shape: torch.Size([1, 128, 113])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 113])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 113])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 113])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 113])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 618/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9210/00014.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9210/00014.wav
Generated Mel Shape: torch.Size([1, 128, 178]), Reference Mel Shape: torch.Size([1, 128, 224])
Generated Mel Shape: torch.Size([1, 128, 178]), Reference Mel Shape: torch.Size([1, 128, 178])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 178])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 178])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 178])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 178])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 23])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 23])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2944])

[Processing Pair 619/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9210/00017.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9210/00017.wav
Generated Mel Shape: torch.Size([1, 128, 165]), Reference Mel Shape: torch.Size([1, 128, 230])
Generated Mel Shape: torch.Size([1, 128, 165]), Reference Mel Shape: torch.Size([1, 128, 165])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 165])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 165])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 165])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 165])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 83])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 42])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 620/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9211/00026.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9211/00026.wav
Generated Mel Shape: torch.Size([1, 128, 190]), Reference Mel Shape: torch.Size([1, 128, 211])
Generated Mel Shape: torch.Size([1, 128, 190]), Reference Mel Shape: torch.Size([1, 128, 190])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 190])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 190])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 95])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 190])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 190])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 95])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 48])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 621/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9211/00029.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9211/00029.wav
Generated Mel Shape: torch.Size([1, 128, 399]), Reference Mel Shape: torch.Size([1, 128, 576])
Generated Mel Shape: torch.Size([1, 128, 399]), Reference Mel Shape: torch.Size([1, 128, 399])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 399])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 399])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 200])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 100])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 50])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 50])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 6400])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 399])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 399])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 200])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 100])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 50])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 50])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 6400])

[Processing Pair 622/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9213/00009.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9213/00009.wav
Generated Mel Shape: torch.Size([1, 128, 89]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 89]), Reference Mel Shape: torch.Size([1, 128, 89])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 89])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 89])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 89])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 45])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 23])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 12])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 12])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1536])

[Processing Pair 623/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9214/00014.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9214/00014.wav
Generated Mel Shape: torch.Size([1, 128, 212]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 153]), Reference Mel Shape: torch.Size([1, 128, 153])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 153])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 153])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 77])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 39])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 20])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 20])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2560])

[Processing Pair 624/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9215/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9215/00011.wav
Generated Mel Shape: torch.Size([1, 128, 155]), Reference Mel Shape: torch.Size([1, 128, 147])
Generated Mel Shape: torch.Size([1, 128, 147]), Reference Mel Shape: torch.Size([1, 128, 147])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 147])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 147])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 147])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 625/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9216/00004.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9216/00004.wav
Generated Mel Shape: torch.Size([1, 128, 112]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 112]), Reference Mel Shape: torch.Size([1, 128, 112])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 112])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 112])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 112])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 56])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 28])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 626/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9217/00019.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9217/00019.wav
Generated Mel Shape: torch.Size([1, 128, 149]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 140]), Reference Mel Shape: torch.Size([1, 128, 140])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 140])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 140])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 70])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 35])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 627/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9219/00004.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9219/00004.wav
Generated Mel Shape: torch.Size([1, 128, 240]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 204]), Reference Mel Shape: torch.Size([1, 128, 204])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 204])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 204])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 204])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 204])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 102])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])

[Processing Pair 628/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9219/00023.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9219/00023.wav
Generated Mel Shape: torch.Size([1, 128, 148]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 148]), Reference Mel Shape: torch.Size([1, 128, 148])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 148])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 148])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 148])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 148])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 74])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 37])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 629/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9219/00025.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9219/00025.wav
Generated Mel Shape: torch.Size([1, 128, 170]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 170]), Reference Mel Shape: torch.Size([1, 128, 170])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 170])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 170])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 85])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 170])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 170])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 85])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 630/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9219/00026.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9219/00026.wav
Generated Mel Shape: torch.Size([1, 128, 163]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 163]), Reference Mel Shape: torch.Size([1, 128, 163])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 163])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 163])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 163])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 163])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 82])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 41])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 21])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 21])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2688])

[Processing Pair 631/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9219/00028.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9219/00028.wav
Generated Mel Shape: torch.Size([1, 128, 251]), Reference Mel Shape: torch.Size([1, 128, 281])
Generated Mel Shape: torch.Size([1, 128, 251]), Reference Mel Shape: torch.Size([1, 128, 251])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 251])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 251])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 126])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 63])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 251])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 251])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 126])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 63])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 32])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 32])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 4096])

[Processing Pair 632/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9220/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9220/00002.wav
Generated Mel Shape: torch.Size([1, 128, 234]), Reference Mel Shape: torch.Size([1, 128, 211])
Generated Mel Shape: torch.Size([1, 128, 211]), Reference Mel Shape: torch.Size([1, 128, 211])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 211])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 211])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 106])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 211])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 211])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 106])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 53])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 27])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 27])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3456])

[Processing Pair 633/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9221/00011.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9221/00011.wav
Generated Mel Shape: torch.Size([1, 128, 227]), Reference Mel Shape: torch.Size([1, 128, 268])
Generated Mel Shape: torch.Size([1, 128, 227]), Reference Mel Shape: torch.Size([1, 128, 227])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 227])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 227])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 114])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 227])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 227])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 114])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 57])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 29])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 29])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3712])

[Processing Pair 634/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9222/00028.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9222/00028.wav
Generated Mel Shape: torch.Size([1, 128, 116]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 116]), Reference Mel Shape: torch.Size([1, 128, 116])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 116])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 116])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 116])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 58])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 29])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 635/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9229/00003.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9229/00003.wav
Generated Mel Shape: torch.Size([1, 128, 118]), Reference Mel Shape: torch.Size([1, 128, 134])
Generated Mel Shape: torch.Size([1, 128, 118]), Reference Mel Shape: torch.Size([1, 128, 118])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 118])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 118])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 118])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 118])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 636/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9230/00006.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9230/00006.wav
Generated Mel Shape: torch.Size([1, 128, 119]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 119]), Reference Mel Shape: torch.Size([1, 128, 119])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 119])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 119])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 119])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 119])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 60])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 637/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9232/00004.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9232/00004.wav
Generated Mel Shape: torch.Size([1, 128, 101]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 101]), Reference Mel Shape: torch.Size([1, 128, 101])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 101])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 101])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 13])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 13])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1664])

[Processing Pair 638/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9233/00010.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9233/00010.wav
Generated Mel Shape: torch.Size([1, 128, 171]), Reference Mel Shape: torch.Size([1, 128, 192])
Generated Mel Shape: torch.Size([1, 128, 171]), Reference Mel Shape: torch.Size([1, 128, 171])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 171])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 171])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 171])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 171])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 86])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 43])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 22])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 22])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2816])

[Processing Pair 639/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9235/00013.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9235/00013.wav
Generated Mel Shape: torch.Size([1, 128, 188]), Reference Mel Shape: torch.Size([1, 128, 185])
Generated Mel Shape: torch.Size([1, 128, 185]), Reference Mel Shape: torch.Size([1, 128, 185])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 185])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 185])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 93])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 185])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 185])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 93])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 47])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 24])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 24])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3072])

[Processing Pair 640/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9237/00021.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9237/00021.wav
Generated Mel Shape: torch.Size([1, 128, 135]), Reference Mel Shape: torch.Size([1, 128, 134])
Generated Mel Shape: torch.Size([1, 128, 134]), Reference Mel Shape: torch.Size([1, 128, 134])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 134])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 134])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 67])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 34])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 17])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 17])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2176])

[Processing Pair 641/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9238/00007.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9238/00007.wav
Generated Mel Shape: torch.Size([1, 128, 152]), Reference Mel Shape: torch.Size([1, 128, 172])
Generated Mel Shape: torch.Size([1, 128, 152]), Reference Mel Shape: torch.Size([1, 128, 152])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 152])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 152])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 152])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 152])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 76])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 38])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 19])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 19])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2432])

[Processing Pair 642/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9239/00002.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9239/00002.wav
Generated Mel Shape: torch.Size([1, 128, 107]), Reference Mel Shape: torch.Size([1, 128, 153])
Generated Mel Shape: torch.Size([1, 128, 107]), Reference Mel Shape: torch.Size([1, 128, 107])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 107])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 107])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 107])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 107])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 54])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 27])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 14])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 14])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1792])

[Processing Pair 643/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9240/00034.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9240/00034.wav
Generated Mel Shape: torch.Size([1, 128, 202]), Reference Mel Shape: torch.Size([1, 128, 204])
Generated Mel Shape: torch.Size([1, 128, 202]), Reference Mel Shape: torch.Size([1, 128, 202])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 202])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 202])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 202])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 202])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 101])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 51])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])

[Processing Pair 644/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9243/00056.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9243/00056.wav
Generated Mel Shape: torch.Size([1, 128, 218]), Reference Mel Shape: torch.Size([1, 128, 198])
Generated Mel Shape: torch.Size([1, 128, 198]), Reference Mel Shape: torch.Size([1, 128, 198])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 198])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 198])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 99])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 198])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 198])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 99])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 50])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 25])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 25])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3200])

[Processing Pair 645/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9246/00018.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9246/00018.wav
Generated Mel Shape: torch.Size([1, 128, 118]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 118]), Reference Mel Shape: torch.Size([1, 128, 118])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 118])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 118])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 118])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 118])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

[Processing Pair 646/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9248/00001.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9248/00001.wav
Generated Mel Shape: torch.Size([1, 128, 208]), Reference Mel Shape: torch.Size([1, 128, 256])
Generated Mel Shape: torch.Size([1, 128, 208]), Reference Mel Shape: torch.Size([1, 128, 208])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 208])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 208])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 104])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 208])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 208])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 104])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 52])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 26])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 26])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 3328])

[Processing Pair 647/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk9249/00008.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk9249/00008.wav
Generated Mel Shape: torch.Size([1, 128, 141]), Reference Mel Shape: torch.Size([1, 128, 179])
Generated Mel Shape: torch.Size([1, 128, 141]), Reference Mel Shape: torch.Size([1, 128, 141])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 141])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 141])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 141])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 71])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 36])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 18])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 18])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 2304])

[Processing Pair 648/648]
Generated: /mnt/qb/work/butz/bst080/faceGANtts/test/synth_voices/spk950/00037.wav
Reference: /mnt/qb/work2/butz1/bst080/data/mvlrs_v1/lrs2_splitted/wav/test/spk950/00037.wav
Generated Mel Shape: torch.Size([1, 128, 117]), Reference Mel Shape: torch.Size([1, 128, 140])
Generated Mel Shape: torch.Size([1, 128, 117]), Reference Mel Shape: torch.Size([1, 128, 117])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 117])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])
[DEBUG] Initial x shape: torch.Size([1, 1, 128, 117])
[DEBUG] Shape after first Conv2D layer: torch.Size([1, 32, 128, 117])
[DEBUG] Shape after Conv2D layer 1: torch.Size([1, 32, 128, 59])
[DEBUG] Shape after Conv2D layer 2: torch.Size([1, 32, 128, 30])
[DEBUG] Shape after Conv2D layer 3: torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (1): torch.Size([1, 32, 128, 15])
[DEBUG] Shape after post-processing Conv2D (2): torch.Size([1, 1, 128, 15])
[DEBUG] Final output shape of SpectrogramDiscriminator: torch.Size([1, 1920])

######## Evaluation Results ########
Mean Speaker Similarity: 0.9997
Mean F0 Error: 105.0383
Mean MCD: 1.2896
Mean STFT Distance: 236.0971
Composite Metric: 98.6924
